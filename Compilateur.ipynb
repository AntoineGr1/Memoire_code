{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution\n",
    "class Convolution:\n",
    "    def __init__(self, kernel, padding, stride, nb_filter, fct_activation):\n",
    "        self.kernel = kernel\n",
    "        self.padding = padding\n",
    "        self.stride = stride\n",
    "        self.nb_filter = nb_filter\n",
    "        self.fct_activation = fct_activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "class InputLayer(Convolution):\n",
    "    def __init__(self, shape, kernel, padding, stride, nb_filter, fct_activation):\n",
    "        self.shape = shape\n",
    "        self.kernel = kernel\n",
    "        self.padding = padding\n",
    "        self.stride = stride\n",
    "        self.nb_filter = nb_filter\n",
    "        self.fct_activation = fct_activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pooling Avg/Max\n",
    "class Pooling:\n",
    "    def __init__(self, op, kernel=2, padding=\"valid\", stride=None):\n",
    "        self.op = op # is the operation wanted (avg/max)\n",
    "        self.kernel = kernel\n",
    "        self.padding = padding\n",
    "        self.stride = stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Flatten\n",
    "class Flatten:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense --> Fully connected layer\n",
    "class Dense:\n",
    "    def __init__(self, nb_neurones, fct_activation):\n",
    "        self.nb_neurones = nb_neurones\n",
    "        self.fct_activation = fct_activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that create CNN with list of layer\n",
    "def create_CNN(list_layers):\n",
    "    str_model_cnn = \"model = keras.models.Sequential([\\n\"\n",
    "    # iterate List of layer\n",
    "    for layer in list_layers:\n",
    "        \n",
    "        # if is Intput\n",
    "        if isinstance(layer, InputLayer):\n",
    "            str_model_cnn += \"\\t\\tkeras.layers.Conv2D({}, kernel_size={}, strides={},  activation={}, input_shape={}, padding={}),\\n\".format(\n",
    "                    layer.nb_filter,\n",
    "                    layer.kernel,\n",
    "                    layer.stride,\n",
    "                    layer.fct_activation,\n",
    "                    layer.shape,\n",
    "                    layer.padding)\n",
    "            \n",
    "            \n",
    "        # if is Convolution\n",
    "        elif isinstance(layer, Convolution):\n",
    "            str_model_cnn += \"\\t\\tkeras.layers.Conv2D({}, kernel_size={}, strides={}, activation={}, padding={}),\\n\".format(\n",
    "                    layer.nb_filter,\n",
    "                    layer.kernel,\n",
    "                    layer.stride,\n",
    "                    layer.fct_activation,\n",
    "                    layer.padding)\n",
    "            \n",
    "        # if is Pooling\n",
    "        elif isinstance(layer, Pooling):\n",
    "            if(layer.op == \"avg\"): # avg Pooling \n",
    "                str_model_cnn += \"\\t\\tkeras.layers.AveragePooling2D(pool_size={}, strides={}, padding={}),\\n\".format(\n",
    "                    layer.kernel,\n",
    "                    layer.stride,\n",
    "                    layer.padding)\n",
    "                \n",
    "            else : # Max Pooling\n",
    "                str_model_cnn += \"\\t\\tkeras.layers.MaxPooling2D(pool_size={}, strides={}, padding={}),\\n\".format(\n",
    "                    layer.kernel,\n",
    "                    layer.stride,\n",
    "                    layer.padding)\n",
    "                \n",
    "        # if is Dense (aka Fully connected layer)\n",
    "        elif isinstance(layer, Dense):\n",
    "            str_model_cnn += \"\\t\\tkeras.layers.Dense({}, activation={}),\\n\".format(\n",
    "                layer.nb_neurones, \n",
    "                layer.fct_activation)\n",
    "            \n",
    "        # if is flatten\n",
    "        elif isinstance(layer, Flatten):\n",
    "            str_model_cnn += \"\\t\\tkeras.layers.Flatten(),\\n\"\n",
    "            \n",
    "        # Not possible\n",
    "        else : print(\"Not Possible\")\n",
    "\n",
    "    # end model \n",
    "    str_model_cnn += \"\\n\\t])\\n\"\n",
    "    return str_model_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json file \n",
    "# return list of layer\n",
    "def getArchitectureFromJsonFile(json_file):\n",
    "    \n",
    "    # get architecture by json file\n",
    "    with open(json_file) as archi_json:\n",
    "        archi = json.load(archi_json)\n",
    "\n",
    "    # instantiate class\n",
    "    list_layer = []\n",
    "    for layer in archi:\n",
    "        parameters = layer[parameters] # get parameters\n",
    "        # if is Input class\n",
    "        if(layer[class] == \"Input\"):\n",
    "            # verify if the padding is int or string\n",
    "            try:\n",
    "                padding = int(parameters[padding])\n",
    "            except:\n",
    "                padding = \"\" + parameters[padding] + \"\"\n",
    "            \n",
    "            # instantiate class and add into the list\n",
    "            list_layer.append(InputLayer(parameters[shape], \n",
    "                                parameters[kernel], \n",
    "                                padding, \n",
    "                                parameters[stride],\n",
    "                                parameters[nb_filter],\n",
    "                                parameters[fct_activation]))\n",
    "\n",
    "        \n",
    "        # if is Pooling class\n",
    "        elif(layer[class] == \"Pooling\"):\n",
    "            try:\n",
    "                padding = int(parameters[padding])\n",
    "            except:\n",
    "                padding = \"\" + parameters[padding] + \"\"\n",
    "                \n",
    "            list_layer.append(Pooling(parameters[op],\n",
    "                                      parameters[kernel],\n",
    "                                      padding,\n",
    "                                      parameters[stride]))\n",
    "            \n",
    "        # if is Convolution class\n",
    "        elif(layer[\"class\"] == \"Convolution\"):\n",
    "            try:\n",
    "                padding = int(parameters[padding])\n",
    "            except:\n",
    "                padding = \"\" + parameters[padding] + \"\"\n",
    "                \n",
    "                \n",
    "            list_layer.append(Convolution(parameters[kernel],\n",
    "                                          padding,\n",
    "                                          parameters[stride],\n",
    "                                          parameters[nb_filter],\n",
    "                                          parameters[fct_activation]))\n",
    "            \n",
    "        # if is Flatten class\n",
    "        elif(layer[\"class\"] == \"Flatten\"):\n",
    "            list_layer.append(Flatten())\n",
    "        \n",
    "        # if is Dense class\n",
    "        elif(layer[\"class\"] == \"Dense\"):\n",
    "            list_layer.append(Dense(parameters[nb_neurones],\n",
    "                                    parameters[fct_activation]))\n",
    "\n",
    "        else : print(\"Error\")\n",
    "    return list_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_py_file(json_file):\n",
    "    s = json_file.split(\".\")\n",
    "    file_name = s[0].split(\"/\")[1]\n",
    "    architecture = getArchitectureFromJsonFile(json_file)\n",
    "    \n",
    "    py_dir = \"architecture_py/\"\n",
    "    # reset file\n",
    "    file_py = open(py_dir + file_name + \".py\", \"w\")\n",
    "    file_py.close()\n",
    "    \n",
    "    file_py = open(py_dir + file_name + \".py\", \"a\") # Open file in writting (a --> append)\n",
    "    \n",
    "    # write import\n",
    "    file_py.write(\"\"\"\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import sys\n",
    "import traceback\n",
    "\"\"\")\n",
    "    \n",
    "    # write train/test data \n",
    "    file_py.write(\"\"\"(train_x, train_y), (test_x, test_y) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# normaliser les pixel 0-255 -> 0-1\n",
    "train_x = train_x / 255.0\n",
    "test_x = test_x / 255.0\n",
    "\n",
    "train_x = tf.expand_dims(train_x, 3)\n",
    "test_x = tf.expand_dims(test_x, 3)\n",
    "\n",
    "val_x = train_x[:5000]\n",
    "val_y = train_y[:5000]\n",
    "\n",
    "\"\"\")\n",
    "    \n",
    "    # try\n",
    "    file_py.write(\"\"\"try:\n",
    "    \"\"\")\n",
    "    \n",
    "    # write architecture model\n",
    "    file_py.write(create_CNN(architecture))\n",
    "    \n",
    "    # write : create png of the model\n",
    "    file_py.write(\"    plot_model(model, show_shapes=True, to_file=\\\"%s\\\")\\n\" % (file_name+\".png\"))\n",
    "    \n",
    "    # write compiler\n",
    "    file_py .write(\"\"\"    model.compile(optimizer='adam', loss=keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'])\\n\"\"\")\n",
    "    \n",
    "    # write model training\n",
    "    file_py.write(\"\"\"    model.fit(train_x, train_y, epochs=5, validation_data=(val_x, val_y))\\n\"\"\")\n",
    "    \n",
    "    # write model evaluation\n",
    "    file_py.write(\"\"\"    print(model.evaluate(test_x, test_y))\\n\"\"\")\n",
    "    \n",
    "    log_file = file_name +\".log\"\n",
    "    file_py.write(\"\"\"\n",
    "    print('OK: file \"\"\" + log_file +\"\"\" has been create')\n",
    "    log_file = open(\\\"\"\"\" + log_file + \"\"\"\\\" , \"w\")\n",
    "    log_file.write(str(model.evaluate(test_x, test_y)))\n",
    "    log_file.close()\n",
    "\"\"\")\n",
    "    \n",
    "    # \n",
    "    error_file = file_name+\"_error.log\"\n",
    "    file_py.write(\"\"\"except:\n",
    "    print('error: file \"\"\" + error_file +\"\"\" has been create')\n",
    "    error_file = open(\\\"\"\"\" + error_file + \"\"\"\\\" , \"w\")\n",
    "    traceback.print_exc(file=error_file)\n",
    "    error_file.close()\n",
    "\"\"\")\n",
    "    \n",
    "    # close\n",
    "    file_py.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation CNN valide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "create_py_file(\"architecture_valid.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation CNN non valide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_py_file(\"architecture_invalid.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create CNN json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"architecture_json/\"\n",
    "file_name = \"archi_random_1.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_py_file(directory+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "612px",
    "left": "62px",
    "top": "110.8px",
    "width": "278.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
