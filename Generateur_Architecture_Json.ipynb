{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jsonobject import *\n",
    "import numpy as np \n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution\n",
    "class Convolution(JsonObject):\n",
    "    kernel = IntegerProperty()\n",
    "    padding = StringProperty()\n",
    "    stride = IntegerProperty()\n",
    "    nb_filter = IntegerProperty()\n",
    "    fct_activation = StringProperty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input \n",
    "class InputLayer(JsonObject):\n",
    "    shape = ListProperty(int)\n",
    "    #shape = StringProperty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pooling Avg/Max\n",
    "class Pooling(JsonObject):\n",
    "    op = StringProperty()\n",
    "    kernel = IntegerProperty(default=2)\n",
    "    padding = StringProperty(default=\"'valid'\")\n",
    "    stride = IntegerProperty(default=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Flatten\n",
    "class Flatten(JsonObject):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense --> Fully connected layer\n",
    "class Dense(JsonObject):\n",
    "    nb_neurones =  IntegerProperty()\n",
    "    fct_activation = StringProperty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel': 7,\n",
       " 'padding': 'valid',\n",
       " 'stride': 2,\n",
       " 'nb_filter': 6,\n",
       " 'fct_activation': 'tanh'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1 = Convolution(kernel=7, padding=\"valid\", stride=2, nb_filter=6, fct_activation=\"tanh\")\n",
    "conv1.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'shape': [28, 28, 1]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputL = InputLayer(shape=[28,28,1])\n",
    "inputL.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'op': 'avg', 'kernel': 2, 'padding': \"'valid'\", 'stride': None}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool1 = Pooling(op = \"avg\")\n",
    "pool1.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_name = [Convolution, InputLayer, Pooling, Flatten, Dense]\n",
    "\n",
    "# Table of hyperparameter value\n",
    "kernel_value = [1, 2, 3, 4, 5, 6, 7]\n",
    "stride_value = [1, 2, 3]\n",
    "padding_value = [\"valid\", \"same\"]\n",
    "#nb_filter_value = [6, 16, 64, 128, 256, 512, 1024, 2048]\n",
    "fct_activation_value = [\"tanh\", \"relu\", \"selu\"]\n",
    "\n",
    "\n",
    "nb_class = 10 # nb_class\n",
    "op_value = ['avg',\"max\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop(size_archi, x):\n",
    "    prob = x*size_archi-1*x\n",
    "    if ( prob < random.randrange(101)):\n",
    "        return True\n",
    "    else : return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_json_file(archi, file_name):\n",
    "    directory = 'architecture_json/'\n",
    "    \n",
    "    # reset file\n",
    "    archi_file = open(directory+file_name, \"w\")\n",
    "    archi_file.close()\n",
    "    \n",
    "    # create file\n",
    "    \n",
    "    archi_file = open(directory+file_name, \"a\") # Open file in writting (a --> append)\n",
    "    archi_file.write(\"\"\"[\n",
    "    \"\"\")\n",
    "    archi_size = len(archi)\n",
    "    i = 0\n",
    "    for l in archi:\n",
    "\n",
    "        str_layer = \"\"\"\\t{\n",
    "            'class':'\"\"\"\n",
    "        str_layer += l.__class__.__name__\n",
    "        str_layer +=\"\"\"',\\n\\t\\t\\t'parameters':\"\"\"\n",
    "        str_layer += str(l.to_json())\n",
    "        str_layer += \"\"\"\\n\\t\\t}\"\"\"\n",
    "        if(i < archi_size-1):\n",
    "            str_layer += \"\"\",\"\"\"\n",
    "            i+=1\n",
    "        str_layer = str_layer.replace(\"'\",\"\\\"\")\n",
    "        \n",
    "        archi_file.write(str_layer)\n",
    "        \n",
    "    archi_file.write(\"\"\"\\n]\"\"\")\n",
    "    archi_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the output \n",
    "# valid vs same\n",
    "def calcul_output(input_size, l):\n",
    "    output_size = 0\n",
    "    if(l.padding == \"valid\"):\n",
    "        kernel = l.kernel\n",
    "        stride = l.stride\n",
    "        while(input_size>=kernel):\n",
    "            input_size -= stride\n",
    "            output_size += 1   \n",
    "    else:\n",
    "        stride = l.stride\n",
    "        if(input_size%stride == 0):\n",
    "            output_size = int(input_size/stride)\n",
    "        else:\n",
    "            output_size = int(input_size/stride)+1\n",
    "    return output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add layer to architecture \n",
    "\n",
    "def addLayer(archi, layer):\n",
    "    input_size = archi[0].shape[0]\n",
    "    feature_extra = archi[1:]\n",
    "    \n",
    "    # add layer if the architecture is empty\n",
    "    if(feature_extra == []):\n",
    "        archi.append(layer)\n",
    "        return 1, archi, calcul_output(input_size,layer)\n",
    "    \n",
    "    else :\n",
    "        # compute size of the output of the last layer\n",
    "        for l in feature_extra: \n",
    "            output_size = calcul_output(input_size, l)\n",
    "            input_size = output_size\n",
    "        \n",
    "        # if we couldn't reduce more\n",
    "        if(input_size == 1):\n",
    "            return 0, archi, input_size\n",
    "        \n",
    "        # if the output size got more than 1 we can add new layer\n",
    "        elif(output_size > 1): \n",
    "            output_size = calcul_output(input_size, layer)\n",
    "            \n",
    "            # if output size got negate is that the layer we want to add is wrong\n",
    "            if(output_size < 1 ):\n",
    "                return -1, archi, input_size\n",
    "            # if output size is bigger than 0 we can add new layer and continue\n",
    "            elif(output_size > 0):\n",
    "                archi.append(layer)\n",
    "                return 1, archi, output_size\n",
    "            # this should not append\n",
    "            else:\n",
    "                return \"Somethink wrong\"\n",
    "    # this should not append\n",
    "    return \"Error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# test to understant padding\n",
    "\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Conv2D, MaxPool2D, AveragePooling2D\n",
    "\n",
    "#model = Sequential(layers=[\n",
    "#    Conv2D(6, 5, input_shape=(28, 28, 1), strides=1, padding=\"same\"),\n",
    "#    MaxPool2D(pool_size=2, strides=2, padding=\"same\"),\n",
    "#    \n",
    "#])\n",
    "\n",
    "#for layer in model.layers:\n",
    "#    print(layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out : 12\n",
      "code : 1\n",
      "out : 3\n",
      "code : 1\n",
      "out : 3\n",
      "code : -1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[InputLayer(shape=[29, 29, 1]),\n",
       " Convolution(fct_activation='tanh', kernel=7, nb_filter=6, padding='valid', stride=2),\n",
       " Convolution(fct_activation='tanh', kernel=7, nb_filter=6, padding='valid', stride=2)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test for the fonction addLayer()\n",
    "architecture = list()\n",
    "architecture.append(InputLayer(shape=[29,29,1]))\n",
    "\n",
    "\n",
    "\n",
    "code, architecture, out = addLayer(architecture.copy(), conv1)\n",
    "\n",
    "print(\"out : \" + str(out))\n",
    "\n",
    "print(\"code : \" + str(code))\n",
    "\n",
    "code, architecture, out = addLayer(architecture.copy(), conv1)\n",
    "\n",
    "print(\"out : \" + str(out))\n",
    "\n",
    "print(\"code : \" + str(code))\n",
    "\n",
    "code, architecture, out = addLayer(architecture.copy(), conv1)\n",
    "\n",
    "print(\"out : \" + str(out))\n",
    "\n",
    "print(\"code : \" + str(code))\n",
    "\n",
    "architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_feature= [Pooling, Convolution]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size : 3\n",
      "nb_filter : 36.0\n",
      "code: 1\n",
      "param : 324.0\n",
      "nb_neurone : 252\n",
      "=====\n",
      "iteration0\n",
      "nb_neurone : 252\n",
      "=====\n",
      "iteration1\n",
      "nb_neurone : 215\n",
      "=====\n",
      "iteration2\n",
      "nb_neurone : 127\n",
      "=====\n",
      "iteration3\n",
      "nb_neurone : 67\n",
      "=====\n",
      "iteration4\n",
      "nb_neurone : 18\n",
      "=====\n",
      "iteration5\n",
      "nb_neurone : 15\n",
      "[InputLayer(shape=[32, 32, 3]), Convolution(fct_activation='selu', kernel=1, nb_filter=18, padding='same', stride=1), Pooling(kernel=6, op='avg', padding='valid', stride=3), Convolution(fct_activation='tanh', kernel=6, nb_filter=36, padding='same', stride=3), Flatten(), Dense(fct_activation='selu', nb_neurones=252), Dense(fct_activation='selu', nb_neurones=215), Dense(fct_activation='selu', nb_neurones=127), Dense(fct_activation='relu', nb_neurones=67), Dense(fct_activation='relu', nb_neurones=18), Dense(fct_activation='tanh', nb_neurones=15), Dense(fct_activation='softmax', nb_neurones=10)]\n",
      "archi_random_1_v.json\n",
      "\n",
      "output size : 1\n",
      "nb_filter : 144.0\n",
      "code: 0\n",
      "param : 144.0\n",
      "nb_neurone : 110\n",
      "=====\n",
      "iteration0\n",
      "nb_neurone : 110\n",
      "=====\n",
      "iteration1\n",
      "nb_neurone : 24\n",
      "[InputLayer(shape=[32, 32, 3]), Convolution(fct_activation='relu', kernel=6, nb_filter=18, padding='valid', stride=3), Pooling(kernel=3, op='max', padding='valid', stride=3), Convolution(fct_activation='selu', kernel=4, nb_filter=36, padding='same', stride=2), Convolution(fct_activation='relu', kernel=2, nb_filter=72, padding='valid', stride=2), Flatten(), Dense(fct_activation='relu', nb_neurones=110), Dense(fct_activation='relu', nb_neurones=24), Dense(fct_activation='softmax', nb_neurones=10)]\n",
      "archi_random_2_v.json\n",
      "\n",
      "output size : 3\n",
      "nb_filter : 36.0\n",
      "code: 1\n",
      "param : 324.0\n",
      "nb_neurone : 53\n",
      "=====\n",
      "iteration0\n",
      "nb_neurone : 53\n",
      "=====\n",
      "iteration1\n",
      "nb_neurone : 44\n",
      "[InputLayer(shape=[32, 32, 3]), Convolution(fct_activation='selu', kernel=6, nb_filter=18, padding='same', stride=1), Pooling(kernel=4, op='max', padding='same', stride=3), Convolution(fct_activation='selu', kernel=5, nb_filter=36, padding='same', stride=1), Pooling(kernel=3, op='avg', padding='valid', stride=3), Flatten(), Dense(fct_activation='tanh', nb_neurones=53), Dense(fct_activation='tanh', nb_neurones=44), Dense(fct_activation='softmax', nb_neurones=10)]\n",
      "archi_random_3_v.json\n",
      "\n",
      "output size : 8\n",
      "nb_filter : 36.0\n",
      "code: 1\n",
      "param : 2304.0\n",
      "nb_neurone : 380\n",
      "=====\n",
      "iteration0\n",
      "nb_neurone : 380\n",
      "=====\n",
      "iteration1\n",
      "nb_neurone : 312\n",
      "=====\n",
      "iteration2\n",
      "nb_neurone : 240\n",
      "=====\n",
      "iteration3\n",
      "nb_neurone : 66\n",
      "=====\n",
      "iteration4\n",
      "nb_neurone : 17\n",
      "=====\n",
      "iteration5\n",
      "nb_neurone : 14\n",
      "[InputLayer(shape=[32, 32, 3]), Convolution(fct_activation='tanh', kernel=2, nb_filter=18, padding='same', stride=1), Pooling(kernel=3, op='avg', padding='valid', stride=1), Convolution(fct_activation='selu', kernel=4, nb_filter=36, padding='valid', stride=1), Pooling(kernel=5, op='max', padding='valid', stride=3), Flatten(), Dense(fct_activation='tanh', nb_neurones=380), Dense(fct_activation='tanh', nb_neurones=312), Dense(fct_activation='tanh', nb_neurones=240), Dense(fct_activation='tanh', nb_neurones=66), Dense(fct_activation='selu', nb_neurones=17), Dense(fct_activation='relu', nb_neurones=14), Dense(fct_activation='softmax', nb_neurones=10)]\n",
      "archi_random_4_v.json\n",
      "\n",
      "output size : 10\n",
      "nb_filter : 18.0\n",
      "code: 1\n",
      "param : 1800.0\n",
      "nb_neurone : 1544\n",
      "=====\n",
      "iteration0\n",
      "nb_neurone : 1544\n",
      "=====\n",
      "iteration1\n",
      "nb_neurone : 264\n",
      "=====\n",
      "iteration2\n",
      "nb_neurone : 186\n",
      "=====\n",
      "iteration3\n",
      "nb_neurone : 86\n",
      "=====\n",
      "iteration4\n",
      "nb_neurone : 50\n",
      "=====\n",
      "iteration5\n",
      "nb_neurone : 29\n",
      "=====\n",
      "iteration6\n",
      "nb_neurone : 22\n",
      "=====\n",
      "iteration7\n",
      "nb_neurone : 12\n",
      "[InputLayer(shape=[32, 32, 3]), Convolution(fct_activation='selu', kernel=2, nb_filter=18, padding='same', stride=2), Pooling(kernel=7, op='avg', padding='valid', stride=1), Flatten(), Dense(fct_activation='selu', nb_neurones=1544), Dense(fct_activation='tanh', nb_neurones=264), Dense(fct_activation='selu', nb_neurones=186), Dense(fct_activation='relu', nb_neurones=86), Dense(fct_activation='tanh', nb_neurones=50), Dense(fct_activation='relu', nb_neurones=29), Dense(fct_activation='selu', nb_neurones=22), Dense(fct_activation='relu', nb_neurones=12), Dense(fct_activation='softmax', nb_neurones=10)]\n",
      "archi_random_5_v.json\n",
      "\n",
      "output size : 3\n",
      "nb_filter : 144.0\n",
      "code: 1\n",
      "param : 1296.0\n",
      "nb_neurone : 896\n",
      "=====\n",
      "iteration0\n",
      "nb_neurone : 896\n",
      "=====\n",
      "iteration1\n",
      "nb_neurone : 770\n",
      "=====\n",
      "iteration2\n",
      "nb_neurone : 78\n",
      "=====\n",
      "iteration3\n",
      "nb_neurone : 65\n",
      "=====\n",
      "iteration4\n",
      "nb_neurone : 53\n",
      "[InputLayer(shape=[32, 32, 3]), Convolution(fct_activation='tanh', kernel=2, nb_filter=18, padding='same', stride=1), Pooling(kernel=5, op='avg', padding='same', stride=3), Convolution(fct_activation='relu', kernel=6, nb_filter=36, padding='same', stride=1), Pooling(kernel=5, op='max', padding='valid', stride=1), Convolution(fct_activation='selu', kernel=2, nb_filter=72, padding='valid', stride=2), Pooling(kernel=2, op='avg', padding='same', stride=1), Convolution(fct_activation='selu', kernel=1, nb_filter=144, padding='same', stride=1), Flatten(), Dense(fct_activation='tanh', nb_neurones=896), Dense(fct_activation='relu', nb_neurones=770), Dense(fct_activation='relu', nb_neurones=78), Dense(fct_activation='selu', nb_neurones=65), Dense(fct_activation='relu', nb_neurones=53), Dense(fct_activation='softmax', nb_neurones=10)]\n",
      "archi_random_6_v.json\n",
      "\n",
      "output size : 1\n",
      "nb_filter : 72.0\n",
      "code: 1\n",
      "param : 72.0\n",
      "nb_neurone : 9\n",
      "[InputLayer(shape=[32, 32, 3]), Convolution(fct_activation='tanh', kernel=3, nb_filter=18, padding='valid', stride=1), Pooling(kernel=2, op='max', padding='same', stride=2), Convolution(fct_activation='selu', kernel=6, nb_filter=36, padding='valid', stride=2), Pooling(kernel=1, op='avg', padding='valid', stride=1), Convolution(fct_activation='relu', kernel=5, nb_filter=72, padding='valid', stride=3), Flatten(), Dense(fct_activation='softmax', nb_neurones=10)]\n",
      "archi_random_7_v.json\n",
      "\n",
      "output size : 2\n",
      "nb_filter : 36.0\n",
      "code: -1\n",
      "param : 144.0\n",
      "nb_neurone : 118\n",
      "=====\n",
      "iteration0\n",
      "nb_neurone : 118\n",
      "=====\n",
      "iteration1\n",
      "nb_neurone : 72\n",
      "=====\n",
      "iteration2\n",
      "nb_neurone : 44\n",
      "=====\n",
      "iteration3\n",
      "nb_neurone : 12\n",
      "[InputLayer(shape=[32, 32, 3]), Convolution(fct_activation='tanh', kernel=4, nb_filter=18, padding='valid', stride=3), Pooling(kernel=6, op='max', padding='same', stride=3), Convolution(fct_activation='relu', kernel=7, nb_filter=36, padding='same', stride=2), Pooling(kernel=1, op='avg', padding='valid', stride=1), Flatten(), Dense(fct_activation='tanh', nb_neurones=118), Dense(fct_activation='relu', nb_neurones=72), Dense(fct_activation='relu', nb_neurones=44), Dense(fct_activation='selu', nb_neurones=12), Dense(fct_activation='softmax', nb_neurones=10)]\n",
      "archi_random_8_v.json\n",
      "\n",
      "output size : 5\n",
      "nb_filter : 144.0\n",
      "code: 1\n",
      "param : 3600.0\n",
      "nb_neurone : 603\n",
      "=====\n",
      "iteration0\n",
      "nb_neurone : 603\n",
      "=====\n",
      "iteration1\n",
      "nb_neurone : 471\n",
      "=====\n",
      "iteration2\n",
      "nb_neurone : 96\n",
      "=====\n",
      "iteration3\n",
      "nb_neurone : 66\n",
      "=====\n",
      "iteration4\n",
      "nb_neurone : 55\n",
      "[InputLayer(shape=[32, 32, 3]), Convolution(fct_activation='relu', kernel=1, nb_filter=18, padding='valid', stride=1), Pooling(kernel=7, op='max', padding='same', stride=1), Convolution(fct_activation='selu', kernel=4, nb_filter=36, padding='valid', stride=2), Pooling(kernel=4, op='avg', padding='same', stride=1), Convolution(fct_activation='tanh', kernel=7, nb_filter=72, padding='same', stride=2), Pooling(kernel=4, op='max', padding='valid', stride=1), Convolution(fct_activation='selu', kernel=1, nb_filter=144, padding='valid', stride=1), Flatten(), Dense(fct_activation='relu', nb_neurones=603), Dense(fct_activation='relu', nb_neurones=471), Dense(fct_activation='relu', nb_neurones=96), Dense(fct_activation='tanh', nb_neurones=66), Dense(fct_activation='selu', nb_neurones=55), Dense(fct_activation='softmax', nb_neurones=10)]\n",
      "archi_random_9_v.json\n",
      "\n",
      "output size : 1\n",
      "nb_filter : 288.0\n",
      "code: 0\n",
      "param : 288.0\n",
      "nb_neurone : 103\n",
      "=====\n",
      "iteration0\n",
      "nb_neurone : 103\n",
      "=====\n",
      "iteration1\n",
      "nb_neurone : 60\n",
      "=====\n",
      "iteration2\n",
      "nb_neurone : 15\n",
      "[InputLayer(shape=[32, 32, 3]), Convolution(fct_activation='selu', kernel=6, nb_filter=18, padding='same', stride=1), Pooling(kernel=3, op='avg', padding='valid', stride=3), Convolution(fct_activation='tanh', kernel=5, nb_filter=36, padding='valid', stride=3), Convolution(fct_activation='selu', kernel=1, nb_filter=72, padding='same', stride=1), Pooling(kernel=1, op='avg', padding='same', stride=1), Convolution(fct_activation='tanh', kernel=6, nb_filter=144, padding='same', stride=3), Flatten(), Dense(fct_activation='selu', nb_neurones=103), Dense(fct_activation='tanh', nb_neurones=60), Dense(fct_activation='relu', nb_neurones=15), Dense(fct_activation='softmax', nb_neurones=10)]\n",
      "archi_random_10_v.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range (1,11):\n",
    "    architecture = list() # init list\n",
    "    \n",
    "    # add Input layer\n",
    "    architecture.append(InputLayer(shape=[32,32,3]))\n",
    "    \n",
    "    nb_filter_value = 6*3 # init nb feature map\n",
    "    output_size = 32   \n",
    "    \n",
    "    # add extraction feature (succession of Pooling/convolution)\n",
    "    # Pooling can't be follow by a Pooling\n",
    "    pooling = True\n",
    "    code = 1 # we can add new layer\n",
    "    j = 2\n",
    "    while((output_size == 32) | (stop(len(architecture),5) & code == 1)):\n",
    "        layer = extraction_feature[random.randrange(2)]\n",
    "        \n",
    "                \n",
    "        kernel=kernel_value[random.randrange(7)]\n",
    "        stride_value_filtered = [value for value in stride_value if value <= kernel]\n",
    "        stride = stride_value_filtered[random.randrange(len(stride_value_filtered))]\n",
    "        \n",
    "        if(pooling | isinstance(layer, Convolution)):\n",
    "            add_layer = Convolution(\n",
    "                    kernel=kernel, \n",
    "                    padding=padding_value[random.randrange(2)], \n",
    "                    stride=stride, \n",
    "                    nb_filter= nb_filter_value,\n",
    "                    fct_activation=fct_activation_value[random.randrange(3)]\n",
    "            )\n",
    "        else: \n",
    "            add_layer = Pooling(\n",
    "                op = op_value[random.randrange(2)],\n",
    "                kernel=kernel, \n",
    "                padding=padding_value[random.randrange(2)], \n",
    "                stride=stride\n",
    "            )\n",
    "        code, architecture, output_size = addLayer(architecture, add_layer)\n",
    "        if(code == 1 & isinstance(add_layer, Convolution)):\n",
    "            pooling = False\n",
    "            nb_filter_value = nb_filter_value*j\n",
    "        else: pooling = True\n",
    "        \n",
    "    \n",
    "    # add flatten Layer\n",
    "    \n",
    "    print(\"output size : \" + str(output_size))\n",
    "    print(\"nb_filter : \" + str(nb_filter_value/2))\n",
    "    print(\"code: \" + str(code))\n",
    "    \n",
    "    architecture.append(Flatten())\n",
    "\n",
    "    param = output_size*output_size*(nb_filter_value/2)\n",
    "    print('param : ' + str(param))\n",
    "    \n",
    "    #nb_layer = random.randrange(1,10)\n",
    "   \n",
    "    #print(\"nb_layer: \"+ str(nb_layer))\n",
    "    \n",
    "    # add Dense Layer\n",
    "    \n",
    "    ## init values\n",
    "    pourcent = random.uniform(10,90)\n",
    "    nb=0\n",
    "    nb_neurones = int(param*pourcent/100)\n",
    "    \n",
    "    print(\"nb_neurone : \" + str(nb_neurones))\n",
    "    while(nb_neurones > nb_class):\n",
    "        print(\"=====\")\n",
    "        print(\"iteration\" + str(nb))\n",
    "        print(\"nb_neurone : \" + str(nb_neurones))\n",
    "        \n",
    "        architecture.append(Dense(\n",
    "                nb_neurones = nb_neurones,\n",
    "                fct_activation = fct_activation_value[random.randrange(3)]\n",
    "        ))\n",
    "        \n",
    "        #incrementation\n",
    "        pourcent = random.uniform(10,90)\n",
    "        nb+=1\n",
    "        nb_neurones = int(nb_neurones*pourcent/100)\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "    architecture.append(Dense(\n",
    "        nb_neurones = nb_class,\n",
    "        fct_activation=\"softmax\"           \n",
    "    ))\n",
    "                        \n",
    "                        \n",
    "    # print architecture\n",
    "    print(architecture)\n",
    "    \n",
    "    # create file\n",
    "    file_name = \"archi_random_%d_v.json\" % i\n",
    "    print(file_name)\n",
    "    print(\"\")\n",
    "    create_json_file(architecture, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idee ajout Resnet\n",
    "- DSL\n",
    "    - Ex: lenet --> ICACAFDDD\n",
    "    - Ex: Resnet --> ICM[CC][CC][CC]AFDDD\n",
    "    - Ex: Densenet --> ICM[[[CC][[CC]][CC]]]FDDD\n",
    "    - Ex: Xception --> ICM[[[CC][CC]][CC]]FDDD\n",
    "- Ensemble (Diagramme de venn)\n",
    "![image](../Sanstitre.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = math.e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.957322735539908"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.log(2*10)*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
