{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jsonobject import *\n",
    "import numpy as np \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution\n",
    "class Convolution(JsonObject):\n",
    "    kernel = IntegerProperty()\n",
    "    padding = StringProperty()\n",
    "    stride = IntegerProperty()\n",
    "    nb_filter = IntegerProperty()\n",
    "    fct_activation = StringProperty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input \n",
    "class InputLayer(JsonObject):\n",
    "    shape = ListProperty(int)\n",
    "    #shape = StringProperty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pooling Avg/Max\n",
    "class Pooling(JsonObject):\n",
    "    op = StringProperty()\n",
    "    kernel = IntegerProperty(default=2)\n",
    "    padding = StringProperty(default=\"'valid'\")\n",
    "    stride = IntegerProperty(default=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Flatten\n",
    "class Flatten(JsonObject):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense --> Fully connected layer\n",
    "class Dense(JsonObject):\n",
    "    nb_neurones =  IntegerProperty()\n",
    "    fct_activation = StringProperty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel': 7,\n",
       " 'padding': 'valid',\n",
       " 'stride': 2,\n",
       " 'nb_filter': 6,\n",
       " 'fct_activation': 'tanh'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1 = Convolution(kernel=7, padding=\"valid\", stride=2, nb_filter=6, fct_activation=\"tanh\")\n",
    "conv1.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'shape': [28, 28, 1]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputL = InputLayer(shape=[28,28,1])\n",
    "inputL.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'op': 'avg', 'kernel': 2, 'padding': \"'valid'\", 'stride': None}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool1 = Pooling(op = \"avg\")\n",
    "pool1.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_name = [Convolution, InputLayer, Pooling, Flatten, Dense]\n",
    "\n",
    "# Table of hyperparameter value\n",
    "kernel_value = [1, 2, 3, 5, 7]\n",
    "stride_value = [1, 2, 3, 4, 5]\n",
    "padding_value = [\"valid\", \"same\"]\n",
    "#nb_filter_value = [6, 16, 64, 128, 256, 512, 1024, 2048]\n",
    "fct_activation_value = [\"tanh\", \"relu\", \"selu\"]\n",
    "nb_neurones_value = [1, 10, 84, 120, 256]\n",
    "op_value = ['avg',\"max\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop(size_archi, x):\n",
    "    prob = x*size_archi\n",
    "    if ( prob < random.randrange(101)):\n",
    "        return True\n",
    "    else : return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_json_file(archi, file_name):\n",
    "    directory = 'architecture_json/'\n",
    "    \n",
    "    # reset file\n",
    "    archi_file = open(directory+file_name, \"w\")\n",
    "    archi_file.close()\n",
    "    \n",
    "    # create file\n",
    "    \n",
    "    archi_file = open(directory+file_name, \"a\") # Open file in writting (a --> append)\n",
    "    archi_file.write(\"\"\"[\n",
    "    \"\"\")\n",
    "    archi_size = len(archi)\n",
    "    i = 0\n",
    "    for l in archi:\n",
    "\n",
    "        str_layer = \"\"\"\\t{\n",
    "            'class':'\"\"\"\n",
    "        str_layer += l.__class__.__name__\n",
    "        str_layer +=\"\"\"',\\n\\t\\t\\t'parameters':\"\"\"\n",
    "        str_layer += str(l.to_json())\n",
    "        str_layer += \"\"\"\\n\\t\\t}\"\"\"\n",
    "        if(i < archi_size-1):\n",
    "            str_layer += \"\"\",\"\"\"\n",
    "            i+=1\n",
    "        str_layer = str_layer.replace(\"'\",\"\\\"\")\n",
    "        \n",
    "        archi_file.write(str_layer)\n",
    "        \n",
    "    archi_file.write(\"\"\"\\n]\"\"\")\n",
    "    archi_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the output \n",
    "# valid vs same\n",
    "def calcul_output(input_size, l):\n",
    "    output_size = 0\n",
    "    if(l.padding == \"valid\"):\n",
    "        kernel = l.kernel\n",
    "        stride = l.stride\n",
    "        while(input_size>=kernel):\n",
    "            input_size -= stride\n",
    "            output_size += 1   \n",
    "    else:\n",
    "        stride = l.stride\n",
    "        output_size = int(input_size/stride)\n",
    "    return output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add layer to architecture \n",
    "\n",
    "def addLayer(archi, layer):\n",
    "    input_size = archi[0].shape[0]\n",
    "    feature_extra = archi[1:]\n",
    "    \n",
    "    # add layer if the architecture is empty\n",
    "    if(feature_extra == []):\n",
    "        archi.append(layer)\n",
    "        return 1, archi.copy()\n",
    "    \n",
    "    else :\n",
    "        # compute size of the output of the last layer\n",
    "        for l in feature_extra: \n",
    "            output_size = calcul_output(input_size, l)\n",
    "            input_size = output_size\n",
    "        \n",
    "        # if we couldn't reduce more\n",
    "        if(output_size == 1):\n",
    "            return 0, archi.copy()\n",
    "        \n",
    "        # if the output size got more than 1 we can add new layer\n",
    "        elif(output_size > 1): \n",
    "            output_size = calcul_output(output_size, layer)\n",
    "            \n",
    "            # if output size got negate is that the layer we want to add is wrong\n",
    "            if(output_size < 1 ):\n",
    "                return -1, archi.copy()\n",
    "            # if output size is bigger than 0 we can add new layer and continue\n",
    "            elif(output_size > 0):\n",
    "                archi.append(layer)\n",
    "                return 1, archi.copy()\n",
    "            # this should not append\n",
    "            else:\n",
    "                return \"Somethink wrong\"\n",
    "    # this should not append\n",
    "    return \"Error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 11, 11, 6)\n",
      "(None, 3, 3, 6)\n"
     ]
    }
   ],
   "source": [
    "# test to understant padding\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "\n",
    "model = Sequential(layers=[\n",
    "    Conv2D(6, 7, input_shape=(28, 28, 1), strides=2, padding=\"valid\"),\n",
    "    MaxPool2D(pool_size=7, strides=5, padding=\"same\")\n",
    "])\n",
    "\n",
    "for layer in model.layers:\n",
    "    print(layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code : 1\n",
      "code : 1\n",
      "code : -1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[InputLayer(shape=[29, 29, 1]),\n",
       " Convolution(fct_activation='tanh', kernel=7, nb_filter=6, padding='valid', stride=2),\n",
       " Convolution(fct_activation='tanh', kernel=7, nb_filter=6, padding='valid', stride=2)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test for the fonction addLayer()\n",
    "architecture = list()\n",
    "architecture.append(InputLayer(shape=[29,29,1]))\n",
    "\n",
    "\n",
    "\n",
    "code, architecture = addLayer(architecture.copy(), conv1)\n",
    "\n",
    "print(\"code : \" + str(code))\n",
    "\n",
    "code, architecture = addLayer(architecture.copy(), conv1)\n",
    "\n",
    "print(\"code : \" + str(code))\n",
    "\n",
    "code, architecture = addLayer(architecture.copy(), conv1)\n",
    "\n",
    "print(\"code : \" + str(code))\n",
    "\n",
    "architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_feature= [Pooling, Convolution]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[InputLayer(shape=[28, 28, 1]), Convolution(fct_activation='selu', kernel=3, nb_filter=6, padding='same', stride=5), Pooling(kernel=1, op='avg', padding='same', stride=4), Flatten(), Dense(fct_activation='softmax', nb_neurones=256)]\n",
      "archi_random_1_v.json\n",
      "\n",
      "[InputLayer(shape=[28, 28, 1]), Convolution(fct_activation='relu', kernel=5, nb_filter=6, padding='same', stride=5), Pooling(kernel=2, op='max', padding='valid', stride=1), Convolution(fct_activation='relu', kernel=3, nb_filter=12, padding='same', stride=4), Flatten(), Dense(fct_activation='tanh', nb_neurones=84), Dense(fct_activation='selu', nb_neurones=10), Dense(fct_activation='softmax', nb_neurones=1)]\n",
      "archi_random_2_v.json\n",
      "\n",
      "[InputLayer(shape=[28, 28, 1]), Convolution(fct_activation='selu', kernel=5, nb_filter=6, padding='valid', stride=1), Pooling(kernel=2, op='avg', padding='same', stride=4), Convolution(fct_activation='relu', kernel=1, nb_filter=12, padding='valid', stride=5), Flatten(), Dense(fct_activation='relu', nb_neurones=120), Dense(fct_activation='softmax', nb_neurones=84)]\n",
      "archi_random_3_v.json\n",
      "\n",
      "[InputLayer(shape=[28, 28, 1]), Convolution(fct_activation='tanh', kernel=2, nb_filter=6, padding='same', stride=4), Pooling(kernel=2, op='max', padding='same', stride=1), Convolution(fct_activation='relu', kernel=2, nb_filter=12, padding='valid', stride=4), Flatten(), Dense(fct_activation='softmax', nb_neurones=1)]\n",
      "archi_random_4_v.json\n",
      "\n",
      "[InputLayer(shape=[28, 28, 1]), Convolution(fct_activation='tanh', kernel=5, nb_filter=6, padding='same', stride=1), Pooling(kernel=5, op='max', padding='same', stride=3), Convolution(fct_activation='selu', kernel=3, nb_filter=12, padding='valid', stride=3), Pooling(kernel=1, op='max', padding='valid', stride=2), Flatten(), Dense(fct_activation='relu', nb_neurones=84), Dense(fct_activation='selu', nb_neurones=10), Dense(fct_activation='softmax', nb_neurones=1)]\n",
      "archi_random_5_v.json\n",
      "\n",
      "[InputLayer(shape=[28, 28, 1]), Convolution(fct_activation='selu', kernel=1, nb_filter=6, padding='valid', stride=3), Pooling(kernel=1, op='avg', padding='same', stride=4), Convolution(fct_activation='relu', kernel=2, nb_filter=12, padding='same', stride=1), Pooling(kernel=1, op='avg', padding='valid', stride=5), Flatten(), Dense(fct_activation='selu', nb_neurones=120), Dense(fct_activation='relu', nb_neurones=84), Dense(fct_activation='selu', nb_neurones=10), Dense(fct_activation='softmax', nb_neurones=1)]\n",
      "archi_random_6_v.json\n",
      "\n",
      "[InputLayer(shape=[28, 28, 1]), Convolution(fct_activation='tanh', kernel=5, nb_filter=6, padding='valid', stride=2), Pooling(kernel=1, op='avg', padding='valid', stride=4), Convolution(fct_activation='relu', kernel=1, nb_filter=12, padding='valid', stride=1), Pooling(kernel=2, op='avg', padding='same', stride=3), Flatten(), Dense(fct_activation='softmax', nb_neurones=1)]\n",
      "archi_random_7_v.json\n",
      "\n",
      "[InputLayer(shape=[28, 28, 1]), Convolution(fct_activation='relu', kernel=1, nb_filter=6, padding='same', stride=1), Pooling(kernel=3, op='max', padding='same', stride=4), Convolution(fct_activation='relu', kernel=2, nb_filter=12, padding='same', stride=4), Flatten(), Dense(fct_activation='softmax', nb_neurones=1)]\n",
      "archi_random_8_v.json\n",
      "\n",
      "[InputLayer(shape=[28, 28, 1]), Convolution(fct_activation='selu', kernel=3, nb_filter=6, padding='valid', stride=3), Pooling(kernel=7, op='avg', padding='same', stride=2), Convolution(fct_activation='tanh', kernel=5, nb_filter=12, padding='same', stride=1), Pooling(kernel=1, op='max', padding='same', stride=2), Convolution(fct_activation='relu', kernel=7, nb_filter=18, padding='same', stride=1), Flatten(), Dense(fct_activation='relu', nb_neurones=10), Dense(fct_activation='softmax', nb_neurones=1)]\n",
      "archi_random_9_v.json\n",
      "\n",
      "[InputLayer(shape=[28, 28, 1]), Convolution(fct_activation='relu', kernel=7, nb_filter=6, padding='same', stride=5), Pooling(kernel=2, op='avg', padding='valid', stride=1), Flatten(), Dense(fct_activation='softmax', nb_neurones=1)]\n",
      "archi_random_10_v.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range (1,11):\n",
    "    architecture = list() # init list\n",
    "    \n",
    "    # add Input layer\n",
    "    architecture.append(InputLayer(shape=[28,28,1]))\n",
    "    \n",
    "    nb_filter = 6 # init nb feature map\n",
    "    \n",
    "    # add convolution layer\n",
    "    architecture.append(Convolution(\n",
    "                kernel=kernel_value[random.randrange(5)], \n",
    "                padding=padding_value[random.randrange(2)], \n",
    "                stride=stride_value[random.randrange(5)], \n",
    "                nb_filter=nb_filter,\n",
    "                fct_activation=fct_activation_value[random.randrange(3)]\n",
    "    ))\n",
    "    \n",
    "    # add extraction feature (succession of Pooling/convolution)\n",
    "    # Pooling can't be follow by a Pooling\n",
    "    pooling = False\n",
    "    code = 1 # \n",
    "    j = 2\n",
    "    while(code == 1):\n",
    "        layer = extraction_feature[random.randrange(2)]\n",
    "        if(pooling | isinstance(layer, Convolution)):\n",
    "            add_layer = Convolution(\n",
    "                    kernel=kernel_value[random.randrange(5)], \n",
    "                    padding=padding_value[random.randrange(2)], \n",
    "                    stride=stride_value[random.randrange(5)], \n",
    "                    nb_filter=nb_filter*j,\n",
    "                    fct_activation=fct_activation_value[random.randrange(3)]\n",
    "            )\n",
    "            j+=1\n",
    "        else: \n",
    "            add_layer = Pooling(\n",
    "                op = op_value[random.randrange(2)],\n",
    "                kernel=kernel_value[random.randrange(5)], \n",
    "                padding=padding_value[random.randrange(2)], \n",
    "                stride=stride_value[random.randrange(5)]\n",
    "            )\n",
    "        code, architecture = addLayer(architecture, add_layer)\n",
    "        if(code == 1 & isinstance(add_layer, Convolution)):\n",
    "            pooling = False\n",
    "        else: pooling = True\n",
    "    \n",
    "    if(not pooling):\n",
    "        pooling = Pooling(\n",
    "            op = op_value[random.randrange(2)],\n",
    "            kernel=kernel_value[random.randrange(5)], \n",
    "            padding=padding_value[random.randrange(2)], \n",
    "            stride=stride_value[random.randrange(5)]\n",
    "        )\n",
    "        code, architecture = addLayer(architecture, pooling)\n",
    "        while(code < 0):\n",
    "            pooling = Pooling(\n",
    "                    op = pooling.op,\n",
    "                    kernel = pooling.kernel-1,\n",
    "                    padding = pooling.padding,\n",
    "                    stride = pooling.stride-1\n",
    "                )\n",
    "            code, architecture = addLayer(architecture, pooling)\n",
    "        \n",
    "    \n",
    "    # add flatten Layer\n",
    "    architecture.append(Flatten())\n",
    "    \n",
    "    # add Dense Layer\n",
    "    nb_neurones = nb_neurones_value[random.randrange(5)]\n",
    "    while((nb_neurones_value.index(nb_neurones)>0) & stop(len(architecture),4)):\n",
    "        architecture.append(Dense(\n",
    "            nb_neurones = nb_neurones,\n",
    "            fct_activation = fct_activation_value[random.randrange(3)]      \n",
    "        ))\n",
    "        nb_neurones = nb_neurones_value[nb_neurones_value.index(nb_neurones)-1]\n",
    "    \n",
    "    architecture.append(Dense(\n",
    "        nb_neurones = nb_neurones,\n",
    "        fct_activation=\"softmax\"           \n",
    "    ))\n",
    "\n",
    "    \n",
    "                        \n",
    "                        \n",
    "    # print architecture\n",
    "    print(architecture)\n",
    "    \n",
    "    # create file\n",
    "    file_name = \"archi_random_%d_v.json\" % i\n",
    "    print(file_name)\n",
    "    print(\"\")\n",
    "    create_json_file(architecture, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
