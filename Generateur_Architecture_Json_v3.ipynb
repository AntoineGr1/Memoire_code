{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jsonobject import *\n",
    "import numpy as np \n",
    "import random\n",
    "import math\n",
    "import networkx as nx\n",
    "from networkx.readwrite import json_graph\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution\n",
    "class Convolution(JsonObject):\n",
    "    kernel = IntegerProperty()\n",
    "    padding = StringProperty()\n",
    "    stride = IntegerProperty()\n",
    "    nb_filter = IntegerProperty()\n",
    "    fct_activation = StringProperty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input \n",
    "class InputLayer(JsonObject):\n",
    "    shape = ListProperty(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pooling Avg/Max\n",
    "class Pooling(JsonObject):\n",
    "    op = StringProperty()\n",
    "    kernel = IntegerProperty(default=2)\n",
    "    padding = StringProperty(default=\"'valid'\")\n",
    "    stride = IntegerProperty(default=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Flatten\n",
    "class Flatten(JsonObject):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense --> Fully connected layer\n",
    "class Dense(JsonObject):\n",
    "    nb_neurones =  IntegerProperty()\n",
    "    fct_activation = StringProperty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identity block \n",
    "class IdBlock(JsonObject):\n",
    "    kernel = IntegerProperty()\n",
    "    padding = StringProperty()\n",
    "    nb_filter = IntegerProperty()\n",
    "    stride = 1\n",
    "    fct_activation = StringProperty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolution block\n",
    "class ConvBlock(JsonObject):\n",
    "    kernel = IntegerProperty()\n",
    "    nb_filter = IntegerProperty()\n",
    "    padding = StringProperty()\n",
    "    stride = IntegerProperty()\n",
    "    fct_activation = StringProperty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enum type archi\n",
    "class TypeArchi(Enum):\n",
    "    ALL = 0\n",
    "    LENET = 1\n",
    "    RESNET = 2\n",
    "    DENSENET = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration Archi\n",
    "class ConfArchi(JsonObject):\n",
    "    type_archi = IntegerProperty()\n",
    "    epsilon = FloatProperty()\n",
    "    dropout_rate = FloatProperty()\n",
    "    compress_factor = FloatProperty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DenseNet Convolution Block \n",
    "class DenseNetBlock(JsonObject):\n",
    "    kernel = IntegerProperty()\n",
    "    nb_filter = IntegerProperty()\n",
    "    padding = StringProperty()\n",
    "    stride = IntegerProperty()\n",
    "    nb_layer = IntegerProperty()\n",
    "    fct_activation = StringProperty()\n",
    "    op = StringProperty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global pooling \n",
    "class GlobalPooling(JsonObject):\n",
    "    op = StringProperty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table of hyperparameter value\n",
    "kernel_value = [2, 3, 4, 5, 6, 7]\n",
    "stride_value = [1, 2, 3, 4, 5, 6, 7]\n",
    "padding_value = [\"'valid'\", \"'same'\"]\n",
    "fct_activation_value = [\"tanh\", \"relu\", \"selu\"]\n",
    "\n",
    "epsilon_value = [None, 1.001e-5, 0.001, 1.1e-5, 1.1e-7]\n",
    "dropout_value = [None, .1, .4, .5, .8, .01, .001]\n",
    "\n",
    "nb_layer_value = [1,2]\n",
    "\n",
    "nb_class = 10 # nb_class\n",
    "op_value = ['avg',\"max\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 1.001e-05, 0.001, 1.1e-05, 1.1e-07]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop(size_archi, x):\n",
    "    prob = (math.log(2*size_archi)*x)-(2*x)\n",
    "    if ( prob < random.randrange(101)):\n",
    "        return True\n",
    "    else : return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_json_file(archi, file_name):\n",
    "    directory = 'architecture_json/'\n",
    "    \n",
    "    # reset file\n",
    "    archi_file = open(directory+file_name, \"w\")\n",
    "    archi_file.close()\n",
    "    \n",
    "    # create file\n",
    "    \n",
    "    # open file\n",
    "    archi_file = open(directory+file_name, \"a\")\n",
    "    \n",
    "    archi_file.write(\"\"\"[\n",
    "    \"\"\")\n",
    "    \n",
    "    archi_size = len(archi)\n",
    "    i = 0\n",
    "    for l in archi:\n",
    "\n",
    "        str_layer = \"\"\"\\t{\n",
    "            'class':'\"\"\"\n",
    "        str_layer += l.__class__.__name__\n",
    "        str_layer +=\"\"\"',\\n\\t\\t\\t'parameters':\"\"\"\n",
    "        str_layer += str(l.to_json())\n",
    "        str_layer += \"\"\"\\n\\t\\t}\"\"\"\n",
    "        if(i < archi_size-1):\n",
    "            str_layer += \"\"\",\"\"\"\n",
    "            i+=1\n",
    "        str_layer = str_layer.replace(\"'\",\"\\\"\")\n",
    "        \n",
    "        archi_file.write(str_layer)\n",
    "        \n",
    "    archi_file.write(\"\"\"\\n]\"\"\")\n",
    "    archi_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the output \n",
    "# valid vs same\n",
    "def calcul_output(input_size, l):\n",
    "    output_size = 0\n",
    "    if(l.padding == \"valid\"):\n",
    "        kernel = l.kernel\n",
    "        stride = l.stride\n",
    "        while(input_size>=kernel):\n",
    "            input_size -= stride\n",
    "            output_size += 1   \n",
    "    else:\n",
    "        stride = l.stride\n",
    "        if(input_size%stride == 0):\n",
    "            output_size = int(input_size/stride)\n",
    "        else:\n",
    "            output_size = int(input_size/stride)+1\n",
    "    return output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add layer to architecture \n",
    "\n",
    "def addLayer(archi, layer):\n",
    "    input_size = archi[0].shape[0]\n",
    "    feature_extra = archi[1:]\n",
    "    \n",
    "    # add layer if the architecture is empty\n",
    "    if(feature_extra == []):\n",
    "        archi.append(layer)\n",
    "        return 1, archi, calcul_output(input_size,layer)\n",
    "    \n",
    "    else :\n",
    "        # compute size of the output of the last layer\n",
    "        for l in feature_extra: \n",
    "            output_size = calcul_output(input_size, l)\n",
    "            input_size = output_size\n",
    "        \n",
    "        # if we couldn't reduce more\n",
    "        if(input_size == 1):\n",
    "            return 0, archi, input_size\n",
    "        \n",
    "        # if the output size got more than 1 we can add new layer\n",
    "        elif(output_size > 1): \n",
    "            output_size = calcul_output(input_size, layer)\n",
    "            \n",
    "            # if output size got negate is that the layer we want to add is wrong\n",
    "            if(output_size < 1 ):\n",
    "                return -1, archi, input_size\n",
    "            # if output size is bigger than 0 we can add new layer and continue\n",
    "            elif(output_size > 0):\n",
    "                archi.append(layer)\n",
    "                return 1, archi, output_size\n",
    "            # this should not append\n",
    "            else:\n",
    "                return \"Somethink wrong\"\n",
    "    # this should not append\n",
    "    return \"Error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "esp = epsilon_value[random.randrange(5)]\n",
    "rate = dropout_value[random.randrange(7)]\n",
    "\n",
    "# we can force the generator to generate one type of architecture in particular\n",
    "type_archi = TypeArchi.DENSENET\n",
    "\n",
    "ca = ConfArchi(type_archi=type_archi.value, epsilon=esp, dropout_rate=rate, compress_factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_extraction_feature = [] # full feature extraction\n",
    "wp_extraction_feature = [] # feature extraction without pooling\n",
    "\n",
    "# all layer\n",
    "if (type_archi == TypeArchi.ALL):\n",
    "    full_extraction_feature= [Convolution, Pooling, IdBlock, ConvBlock, DenseNetBlock] \n",
    "    wp_extraction_feature= [Convolution, IdBlock, ConvBlock, DenseNetBlock] \n",
    "# if Lenet\n",
    "elif (type_archi == TypeArchi.LENET):\n",
    "    full_extraction_feature = [Convolution, Pooling]\n",
    "    wp_extraction_feature = [Convolution]\n",
    "# if resnet\n",
    "elif (type_archi == TypeArchi.RESNET):\n",
    "    full_extraction_feature= [Convolution, Pooling, IdBlock, ConvBlock]\n",
    "    wp_extraction_feature= [Convolution, IdBlock, ConvBlock]\n",
    "# if denset\n",
    "else: \n",
    "    full_extraction_feature= [Convolution, Pooling, DenseNetBlock]\n",
    "    wp_extraction_feature= [Convolution, DenseNetBlock]\n",
    "\n",
    "classification = [Flatten, GlobalPooling]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation d'architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size : 7\n",
      "nb_filter : 6\n",
      "code: 1\n",
      "<class '__main__.GlobalPooling'>\n",
      "[InputLayer(shape=[28, 28, 1]), Convolution(fct_activation='relu', kernel=3, nb_filter=6, padding='same', stride=1), DenseNetBlock(fct_activation='relu', kernel=3, nb_filter=6, nb_layer=2, op='avg', padding='same', stride=2), DenseNetBlock(fct_activation='selu', kernel=3, nb_filter=6, nb_layer=2, op='max', padding='same', stride=1), DenseNetBlock(fct_activation='tanh', kernel=5, nb_filter=6, nb_layer=2, op='avg', padding='same', stride=2), GlobalPooling(op='max'), Dense(fct_activation='softmax', nb_neurones=10), ConfArchi(compress_factor=0.5, dropout_rate=0.001, epsilon=1.1e-05, type_archi=3)]\n",
      "archi_V3_test.json\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "architecture = list()\n",
    "\n",
    "nb_filter_value = 1 # init nb feature map\n",
    "output_size = 28\n",
    "\n",
    "# add input Layer\n",
    "architecture.append(InputLayer(shape=[28,28,1]))\n",
    "\n",
    "# add extraction feature (succession of Pooling/convolution)\n",
    "# Pooling can't be follow by a Pooling\n",
    "pooling = True\n",
    "code = 1 # we can add new layer\n",
    "j = 6\n",
    "while((output_size == 32) | ((stop(len(architecture),7)) & (code == 1))):\n",
    "    # not get 2 pooling in a row\n",
    "    if(pooling):\n",
    "        layer = wp_extraction_feature[random.randrange(len(wp_extraction_feature))]\n",
    "        pooling = False\n",
    "    else:\n",
    "        layer = full_extraction_feature[random.randrange(len(full_extraction_feature))]\n",
    "        if(layer == Pooling):\n",
    "            pooling = True\n",
    "            \n",
    "    # incrementation of number of filter\n",
    "    if(layer == Convolution or layer == ConvBlock):\n",
    "        nb_filter_value = nb_filter_value*j\n",
    "        j=2\n",
    "\n",
    "        \n",
    "        \n",
    "    # kernel >= stride\n",
    "    kernel=kernel_value[random.randrange(6)]\n",
    "    stride_value_filtered = [value for value in stride_value if value <= kernel]\n",
    "    stride = stride_value_filtered[random.randrange(len(stride_value_filtered))]\n",
    "    \n",
    "    # if layer is Convolution\n",
    "    if(layer == Convolution):\n",
    "        add_layer = Convolution(\n",
    "            kernel=kernel, \n",
    "            padding=padding_value[random.randrange(2)], \n",
    "            stride=stride, \n",
    "            nb_filter= nb_filter_value,\n",
    "            fct_activation=fct_activation_value[random.randrange(3)]\n",
    "        )\n",
    "    # if is pooling\n",
    "    elif(layer == Pooling):\n",
    "        add_layer = Pooling(\n",
    "            op = op_value[random.randrange(2)],\n",
    "            kernel=kernel, \n",
    "            padding=padding_value[random.randrange(2)], \n",
    "            stride=stride\n",
    "        )\n",
    "    # if is identity block\n",
    "    elif(layer == IdBlock):\n",
    "        add_layer = IdBlock(\n",
    "            kernel=kernel, \n",
    "            padding='same', \n",
    "            nb_filter=nb_filter_value, \n",
    "            fct_activation=fct_activation_value[random.randrange(3)])\n",
    "        # if is convolution block\n",
    "    elif (layer == ConvBlock):\n",
    "        add_layer = ConvBlock(\n",
    "            kernel=kernel, \n",
    "            nb_filter=nb_filter_value, \n",
    "            padding='same', \n",
    "            stride=stride,\n",
    "            fct_activation=fct_activation_value[random.randrange(3)])\n",
    "    elif (layer == DenseNetBlock):\n",
    "        add_layer = DenseNetBlock( \n",
    "            kernel = kernel, \n",
    "            nb_filter = nb_filter_value, \n",
    "            padding='same', \n",
    "            nb_layer = nb_layer_value[random.randrange(2)],\n",
    "            stride = stride,\n",
    "            fct_activation=fct_activation_value[random.randrange(3)],\n",
    "            op = op_value[random.randrange(2)]\n",
    "        )\n",
    "    else: \n",
    "        print(\"error\")\n",
    "    \n",
    "    code, architecture, output_size = addLayer(architecture, add_layer)\n",
    "\n",
    "try:\n",
    "    nb_filter_value = architecture[len(architecture)-1]['nb_filter']\n",
    "except:\n",
    "    nb_filter_value = int(nb_filter_value/2)\n",
    "\n",
    "print(\"output size : \" + str(output_size))\n",
    "print(\"nb_filter : \" + str(nb_filter_value))\n",
    "print(\"code: \" + str(code))\n",
    "\n",
    "\n",
    "clf_layer = classification[random.randrange(2)]\n",
    "print(clf_layer)\n",
    "if clf_layer == Flatten:\n",
    "    # add flatten layer\n",
    "    architecture.append(Flatten())\n",
    "\n",
    "\n",
    "    # compute parameters\n",
    "    param = output_size*output_size*(nb_filter_value)\n",
    "    print('param : ' + str(param))\n",
    "\n",
    "\n",
    "    ## init values\n",
    "    nb=0\n",
    "    if (param >= 1000):\n",
    "        nb_neurones = int(param*20/100)\n",
    "        print(\"=====\")\n",
    "        print(\"iteration\" + str(nb))\n",
    "        print(\"nb_neurone : \" + str(nb_neurones))\n",
    "        dense = Dense(\n",
    "            nb_neurones = nb_neurones,\n",
    "            fct_activation = fct_activation_value[random.randrange(3)]\n",
    "        )\n",
    "        architecture.append(dense)\n",
    "        nb+=1\n",
    "        nb_neurones = int(nb_neurones*20/100)\n",
    "        \n",
    "    else:\n",
    "        pourcent = random.uniform(10,90)\n",
    "        nb_neurones = int(param*pourcent/100)\n",
    "\n",
    "    while(nb_neurones >= 1000):\n",
    "        print(\"=====\")\n",
    "        print(\"iteration\" + str(nb))\n",
    "        print(\"nb_neurone : \" + str(nb_neurones))\n",
    "        dense = Dense(\n",
    "            nb_neurones = nb_neurones,\n",
    "            fct_activation = fct_activation_value[random.randrange(3)]\n",
    "        )\n",
    "        architecture.append(dense)\n",
    "        nb+=1\n",
    "        nb_neurones = int(nb_neurones*20/100)\n",
    "        \n",
    "        \n",
    "    ## add dense Layers\n",
    "    while(nb_neurones > nb_class*10):\n",
    "        print(\"=====\")\n",
    "        print(\"iteration\" + str(nb))\n",
    "        print(\"nb_neurone : \" + str(nb_neurones))\n",
    "\n",
    "        dense = Dense(\n",
    "            nb_neurones = nb_neurones,\n",
    "            fct_activation = fct_activation_value[random.randrange(3)]\n",
    "        )\n",
    "        architecture.append(dense)\n",
    "\n",
    "\n",
    "        #incrementation\n",
    "        pourcent = random.uniform(10,90)\n",
    "        nb+=1\n",
    "        nb_neurones = int(nb_neurones*pourcent/100)\n",
    "    \n",
    "elif (clf_layer == GlobalPooling):\n",
    "    architecture.append(GlobalPooling(op=op_value[random.randrange(2)]))\n",
    "else: print(clf_layer == GlobalPooling)\n",
    "    \n",
    "\n",
    "last_dense = Dense(\n",
    "    nb_neurones = nb_class,\n",
    "    fct_activation=\"softmax\"           \n",
    ")\n",
    "\n",
    "architecture.append(last_dense)\n",
    "\n",
    "# ajout config\n",
    "architecture.append(ca)\n",
    "\n",
    "# print architecture\n",
    "print(architecture)\n",
    "\n",
    "# create file\n",
    "file_name = \"archi_V3_test.json\"\n",
    "print(file_name)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "create_json_file(architecture, file_name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
