{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1022,
   "id": "a4470016",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jsonobject import *\n",
    "import numpy as np \n",
    "import random\n",
    "import math\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "id": "7488ee9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649ac400",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1024,
   "id": "5e885173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution\n",
    "class Convolution(JsonObject):\n",
    "    kernel = IntegerProperty()\n",
    "    padding = StringProperty()\n",
    "    stride = IntegerProperty()\n",
    "    nb_filter = IntegerProperty()\n",
    "    fct_activation = StringProperty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "id": "289249b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input \n",
    "class InputLayer(JsonObject):\n",
    "    shape = ListProperty(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1026,
   "id": "a60167d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pooling Avg/Max\n",
    "class Pooling(JsonObject):\n",
    "    op = StringProperty()\n",
    "    kernel = IntegerProperty(default=2)\n",
    "    padding = StringProperty(default=\"valid\")\n",
    "    stride = IntegerProperty(default=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1027,
   "id": "f010355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Flatten\n",
    "class Flatten(JsonObject):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1028,
   "id": "d8b40a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense --> Fully connected layer\n",
    "class Dense(JsonObject):\n",
    "    nb_neurones =  IntegerProperty()\n",
    "    fct_activation = StringProperty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1029,
   "id": "63c0b3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batchnorm\n",
    "class BatchNormalisation(JsonObject):\n",
    "    epsilon = FloatProperty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1030,
   "id": "a5a61fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global pooling \n",
    "class GlobalPooling(JsonObject):\n",
    "    op = StringProperty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1031,
   "id": "c88668a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classe for the different possible merge add/concatenate\n",
    "class Merge(JsonObject):\n",
    "    m_type = StringProperty()\n",
    "    sub_SM_1 = ListProperty(JsonObject)\n",
    "    sub_SM_2 = ListProperty(JsonObject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1032,
   "id": "431d96d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class dropout\n",
    "class Dropout(JsonObject):\n",
    "    dropout_rate = FloatProperty()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1033,
   "id": "aa7d7eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class that represente when the way of merge is empty\n",
    "class Empty(JsonObject):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16be5340",
   "metadata": {},
   "source": [
    "# Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1034,
   "id": "b291447b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table of hyperparameter value\n",
    "kernel_value = [1, 2, 3, 4, 5, 6, 7]\n",
    "stride_value = [1, 2, 3, 4, 5, 6, 7]\n",
    "padding_value = [\"valid\", \"same\"]\n",
    "fct_activation_value = [\"tanh\", \"relu\", \"selu\"]\n",
    "\n",
    "epsilon_value = [0, 1.001e-5, 0.001, 1.1e-5, 1.1e-7]\n",
    "dropout_value = [0, .1, .4, .5, .8, .01, .001]\n",
    "\n",
    "nb_layer_value = [1,2,3,4,5,6]\n",
    "\n",
    "nb_class = 10 # nb_class\n",
    "op_value = ['avg',\"max\"]\n",
    "\n",
    "m_type_value = [\"add\", \"concatenate\"]\n",
    "\n",
    "classification = [Flatten, GlobalPooling]\n",
    "\n",
    "merge_type = [\"full\", \"empty\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be668f9",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1035,
   "id": "f4edaa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equals_sm1_sm2(ssm1, ssm2):\n",
    "    try:\n",
    "        i = 0\n",
    "        while (i<len(ssm1)):\n",
    "            if (ssm1[i] != ssm2[i]):\n",
    "                return False\n",
    "            i+=1\n",
    "        return True\n",
    "    except: return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1036,
   "id": "848fafb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop(size_archi, x):\n",
    "    prob = (math.log(2*size_archi)*x)-(2*x)\n",
    "    if ( prob < random.randrange(101)):\n",
    "        return True\n",
    "    else : return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1037,
   "id": "b7b9c342",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Create Json file\n",
    "def create_json_file(archi, file_name):\n",
    "    directory = 'architecture_json/'\n",
    "    \n",
    "    # reset file\n",
    "    archi_file = open(directory+file_name, \"w\")\n",
    "    archi_file.close()\n",
    "    \n",
    "    # create file\n",
    "    \n",
    "    # open file\n",
    "    archi_file = open(directory+file_name, \"a\")\n",
    "    \n",
    "    archi_file.write(\"\"\"[\n",
    "    \"\"\")\n",
    "    \n",
    "    archi_size = len(archi)\n",
    "    i = 0\n",
    "    for l in archi:\n",
    "        if(isinstance(l, Merge)):\n",
    "            str_layer = \"\"\"{\n",
    "        'class':'\"\"\"\n",
    "            str_layer += l.__class__.__name__\n",
    "            str_layer +=\"\"\"',\\n\\t\\t'parameters':{\"\"\"\n",
    "            str_layer += \"'m_type': '\" + str(l.m_type) + \"',\"\n",
    "            str_layer += \"\\n\\t\\t\\t'sub_SM_1': [\\n\\t\\t\"\n",
    "            j = 0\n",
    "            for sl in l.sub_SM_1:\n",
    "                str_layer += \"\"\"\\t\\t\\t{\n",
    "                    'class':'\"\"\"\n",
    "                str_layer += sl.__class__.__name__\n",
    "                str_layer +=\"\"\"',\\n\\t\\t\\t\\t\\t'parameters':\"\"\"\n",
    "                str_layer += str(sl.to_json())\n",
    "                str_layer += \"\"\"\\n\\t\\t\\t\\t}\"\"\"\n",
    "                \n",
    "                if(j < len(l.sub_SM_1)-1):\n",
    "                    str_layer += \"\"\",\"\"\"\n",
    "                    j+=1\n",
    "            str_layer += \"],\"        \n",
    "            str_layer += \"\\n\\t\\t\\t'sub_SM_2': [\\n\"\n",
    "            j = 0\n",
    "            for sl in l.sub_SM_2:\n",
    "                str_layer += \"\"\"\\t\\t\\t\\t{\n",
    "                    'class':'\"\"\"\n",
    "                str_layer += sl.__class__.__name__\n",
    "                str_layer +=\"\"\"',\\n\\t\\t\\t\\t\\t'parameters':\"\"\"\n",
    "                str_layer += str(sl.to_json())\n",
    "                str_layer += \"\"\"\\n\\t\\t\\t\\t}\"\"\"\n",
    "                \n",
    "                if(j < len(l.sub_SM_2)-1):\n",
    "                    str_layer += \"\"\",\"\"\"\n",
    "                    j+=1\n",
    "            \n",
    "            str_layer += \"]\" \n",
    "            str_layer += \"\"\"}\\n\\t\\t}\"\"\"\n",
    "            if( i < archi_size-1):\n",
    "                str_layer += \"\"\",\"\"\"\n",
    "                i+=1\n",
    "            str_layer = str_layer.replace(\"'\",\"\\\"\")\n",
    "        else: \n",
    "            str_layer = \"\"\"{\n",
    "        'class':'\"\"\"\n",
    "            str_layer += l.__class__.__name__\n",
    "            str_layer +=\"\"\"',\\n\\t\\t'parameters':\"\"\"\n",
    "            str_layer += str(l.to_json())\n",
    "            str_layer += \"\"\"\\n\\t}\"\"\"\n",
    "            if(i < archi_size-1):\n",
    "                str_layer += \"\"\",\"\"\"\n",
    "                i+=1\n",
    "            str_layer = str_layer.replace(\"'\",\"\\\"\")\n",
    "        \n",
    "        archi_file.write(str_layer)\n",
    "        \n",
    "    archi_file.write(\"\"\"\\n]\"\"\")\n",
    "    archi_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1038,
   "id": "162232b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantate the layer to add\n",
    "def construct_layer(layer, nb_filter_value, kernel=None, stride=None, padding=None):\n",
    "    \n",
    "    if(kernel == None):    \n",
    "        # Kernel <= output/2\n",
    "        if(output_size == 2):\n",
    "            kernel_value_filtered = [1,2]\n",
    "        elif(output_size == 1):\n",
    "            kernel_value_filtered = [1]\n",
    "        else: \n",
    "            kernel_value_filtered = [value for value in kernel_value if value <= math.ceil(output_size/2)]\n",
    "\n",
    "        kernel=kernel_value_filtered[random.randrange(len(kernel_value_filtered))]\n",
    "    \n",
    "    if(stride == None):\n",
    "        # kernel >= stride\n",
    "        stride_value_filtered = [value for value in stride_value if value <= kernel]\n",
    "        stride = stride_value_filtered[random.randrange(len(stride_value_filtered))]\n",
    "    \n",
    "    if(padding == None):\n",
    "        padding=padding_value[random.randrange(2)]\n",
    "    # if layer is Convolution\n",
    "    if(layer == Convolution):\n",
    "        add_layer = Convolution(\n",
    "            kernel=kernel, \n",
    "            padding=padding, \n",
    "            stride=stride, \n",
    "            nb_filter= nb_filter_value,\n",
    "            fct_activation=fct_activation_value[random.randrange(3)]\n",
    "        )\n",
    "    \n",
    "    # if is pooling\n",
    "    elif(layer == Pooling):\n",
    "        add_layer = Pooling(\n",
    "            op = op_value[random.randrange(2)],\n",
    "            kernel=kernel, \n",
    "            padding=padding, \n",
    "            stride=stride\n",
    "        )\n",
    "    #if is BN\n",
    "    elif(layer == BatchNormalisation):\n",
    "        add_layer = BatchNormalisation(epsilon = epsilon_value[random.randrange(len(epsilon_value))])\n",
    "        \n",
    "    #if dropout\n",
    "    elif(layer == Dropout):\n",
    "        add_layer = Dropout(dropout_rate = dropout_value[random.randrange(len(dropout_value))])\n",
    "    \n",
    "    # if Empty\n",
    "    elif(layer == Empty):\n",
    "        add_layer = Empty()\n",
    "            \n",
    "    else: \n",
    "        print(\"construct layer error\")\n",
    "    \n",
    "    return add_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1039,
   "id": "e79d5d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add layer to architecture \n",
    "\n",
    "def addLayer(archi, add_layer, output_size):\n",
    "    \n",
    "    input_size = output_size\n",
    "    feature_extra = archi[1:]\n",
    "    \n",
    "    if( (add_layer == Dropout) | (add_layer == BatchNormalisation)):\n",
    "        archi.append(add_layer)\n",
    "        return 1, archi, output_size\n",
    "    \n",
    "    # add layer if the architecture is empty\n",
    "    elif(feature_extra == []):\n",
    "        archi.append(add_layer)\n",
    "        return 1, archi, calcul_output(input_size, add_layer)\n",
    "    \n",
    "    else :\n",
    "        \n",
    "        # if we couldn't reduce more\n",
    "        #if(input_size == 1):\n",
    "        #    return 0, archi, input_size\n",
    "        \n",
    "        # if the output size got more than 1 we can add new layer\n",
    "        if(output_size >= 1): \n",
    "            output_size = calcul_output(input_size, add_layer)\n",
    "            \n",
    "            # if output size got negate is that the layer we want to add is wrong\n",
    "            if(output_size < 1 ):\n",
    "                return -1, archi, input_size\n",
    "            # if output size is bigger than 0 we can add new layer and continue\n",
    "            elif(output_size > 0):\n",
    "                archi.append(add_layer)\n",
    "                return 1, archi, output_size\n",
    "            # this should not append\n",
    "            else:\n",
    "                return \"Somethink wrong\"\n",
    "    # this should not append\n",
    "    return \"Error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1040,
   "id": "d310cc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the output \n",
    "# valid vs same\n",
    "def calcul_output(input_size, l):\n",
    "    output_size = 0\n",
    "    \n",
    "    if( (isinstance(l, Empty)) | (isinstance(l, BatchNormalisation)) | (isinstance(l, Dropout))):\n",
    "        return input_size\n",
    "    if(l.padding == \"valid\"):\n",
    "        kernel = l.kernel\n",
    "        stride = l.stride\n",
    "        while(input_size>=kernel):\n",
    "            input_size -= stride\n",
    "            output_size += 1   \n",
    "    else:\n",
    "        stride = l.stride\n",
    "        if(input_size%stride == 0):\n",
    "            output_size = int(input_size/stride)\n",
    "        else:\n",
    "            output_size = int(input_size/stride)+1\n",
    "    return output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "id": "28c221c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_empty_merge(sm, output, nb_filter_value):\n",
    "    nb_layer = random.randrange(len(nb_layer_value))\n",
    "    for i in range(0, nb_layer):\n",
    "        \n",
    "        if(len(sm) > 2):\n",
    "            layer = getSub_SM_Layer(last_layer=sm[len(sm)-1], prev_last_layer=sm[len(sm)-2], tag=\"empty\")\n",
    "        elif(len(sm)>1):\n",
    "            layer = getSub_SM_Layer(last_layer=sm[len(sm)-1], tag=\"empty\")\n",
    "        else:\n",
    "            layer = getSub_SM_Layer(tag=\"empty\")\n",
    "        \n",
    "        if(output == 2):\n",
    "            kernel_value_filtered = [1,2]\n",
    "        elif(output == 1):\n",
    "            kernel_value_filtered = [1]\n",
    "        else: \n",
    "            kernel_value_filtered = [value for value in kernel_value if value <= math.ceil(output/2)]\n",
    "\n",
    "        kernel=kernel_value_filtered[random.randrange(len(kernel_value_filtered))]\n",
    "        \n",
    "        \n",
    "        add_layer = construct_layer(layer, nb_filter_value, padding=\"same\", stride=1, kernel=kernel)\n",
    "        _, sm, output = addLayer(sm, add_layer, output)\n",
    "        \n",
    "    return sm, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "id": "57296599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the merge part \n",
    "def build_merge(archi, output_size, nb_filter_value):\n",
    "    sub_sm1 = list()\n",
    "    sub_sm2 = list()\n",
    "    m_type = m_type_value[random.randrange(2)]\n",
    "    \n",
    "    #m_type = merge_type[random.randrange(2)]\n",
    "    m_type = merge_type[1]\n",
    "    \n",
    "    if(m_type == \"empty\"):\n",
    "        sub_sm1, output_size_sm1 = build_empty_merge(sub_sm1, output_size, nb_filter_value)\n",
    "        add_layer = construct_layer(Empty, nb_filter_value)\n",
    "        _, sub_sm2, output_size_sm2 = addLayer(sub_sm2, add_layer, output_size)\n",
    "    \n",
    "    else: \n",
    "        print(\"non empty\")\n",
    "    \n",
    "    m = Merge(m_type=m_type,\n",
    "             sub_SM_1=sub_sm1,\n",
    "             sub_SM_2=sub_sm2)\n",
    "    \n",
    "    if(equals_sm1_sm2(sub_sm1, sub_sm2)):\n",
    "        #build_merge(archi, output_size)\n",
    "        print(\"equals\")\n",
    "        return archi, output_size\n",
    "    else: \n",
    "        archi.append(m)\n",
    "        return archi , output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "id": "c8d0e36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution, Pooling, BatchNormalisation,  Dropout, Merge, Empty\n",
    "# Return list of layer compared to last layer for the sub state machine\n",
    "def getSub_SM_Layer(last_layer=None, prev_last_layer= None, tag=\"init\"):\n",
    "    list_layer = list()\n",
    "    if(tag == \"init\"):\n",
    "        list_layer = [Convolution, BatchNormalisation] # Merge\n",
    "    \n",
    "    elif(tag == \"empty\"):\n",
    "        if(isinstance(last_layer, Convolution)):\n",
    "                list_layer = [Convolution, BatchNormalisation, Dropout]\n",
    "        elif(isinstance(last_layer, BatchNormalisation)):\n",
    "            if(isinstance(prev_last_layer, Convolution)):\n",
    "                list_layer = [Convolution, Dropout]\n",
    "            else: list_layer = [Convolution]\n",
    "        else: list_layer = [Convolution]\n",
    "    else: \n",
    "        if(isinstance(last_layer, Convolution)):\n",
    "            list_layer = [Convolution, Pooling, BatchNormalisation, Dropout]\n",
    "        elif(isinstance(last_layer, Pooling)):\n",
    "            list_layer = [Convolution]\n",
    "        elif(isinstance(last_layer, BatchNormalisation)):\n",
    "            if(isinstance(prev_last_layer, Convolution)):\n",
    "                list_layer = [Convolution, Pooling, Dropout]\n",
    "            else: list_layer = [Convolution]\n",
    "        elif(isinstance(last_layer, Dropout)):\n",
    "            list_layer = [Pooling]\n",
    "    return list_layer[random.randrange(len(list_layer))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "id": "8de616e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution, Pooling, BatchNormalisation, Dropout, Merge\n",
    "# Return list of layer compared to last layer\n",
    "def getlayer(last_layer, prev_last_layer):\n",
    "    list_layer = list()\n",
    "    if(isinstance(last_layer, InputLayer)):\n",
    "        list_layer = [Convolution, BatchNormalisation, Merge]\n",
    "    elif(isinstance(last_layer, Convolution)):\n",
    "        list_layer = [Convolution, Pooling, BatchNormalisation,  Dropout, Merge]\n",
    "    elif(isinstance(last_layer, Pooling)):\n",
    "        list_layer = [Convolution, Merge]\n",
    "    elif(isinstance(last_layer, BatchNormalisation)):\n",
    "        if(isinstance(prev_last_layer, Convolution)):\n",
    "            list_layer = [Convolution, Merge, Pooling, Dropout]\n",
    "        else: list_layer = [Convolution]\n",
    "    elif(isinstance(last_layer, Dropout)):\n",
    "        list_layer = [Pooling]\n",
    "    elif(isinstance(last_layer, Merge)):\n",
    "        list_layer = [Convolution, BatchNormalisation, Merge]\n",
    "    else: \n",
    "        print(\"getLayer error\")\n",
    "        print(last_layer)\n",
    "    return list_layer[random.randrange(len(list_layer))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440fafd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f018f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f571dfc",
   "metadata": {},
   "source": [
    "# Creation Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "id": "77f68bd3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size : 2\n",
      "nb_filter : 24\n",
      "code: 1\n",
      "<class '__main__.GlobalPooling'>\n",
      "[InputLayer(shape=[28, 28, 1]), Merge(m_type='empty', sub_SM_1=[Convolution(fct_activation='relu', kernel=4, nb_filter=1, padding='same', stride=1)], sub_SM_2=[Empty()]), BatchNormalisation(epsilon=1.001e-05), Convolution(fct_activation='tanh', kernel=6, nb_filter=6, padding='same', stride=6), Dropout(dropout_rate=0.01), Pooling(kernel=3, op='avg', padding='same', stride=2), Convolution(fct_activation='tanh', kernel=2, nb_filter=12, padding='same', stride=2), Merge(m_type='empty', sub_SM_1=[Convolution(fct_activation='tanh', kernel=2, nb_filter=12, padding='same', stride=1), Convolution(fct_activation='tanh', kernel=1, nb_filter=12, padding='same', stride=1), Dropout(dropout_rate=0.1)], sub_SM_2=[Empty()]), Merge(m_type='empty', sub_SM_1=[Convolution(fct_activation='relu', kernel=1, nb_filter=12, padding='same', stride=1), Convolution(fct_activation='tanh', kernel=1, nb_filter=12, padding='same', stride=1), Dropout(dropout_rate=0.01), Convolution(fct_activation='selu', kernel=1, nb_filter=12, padding='same', stride=1), BatchNormalisation(epsilon=0.001)], sub_SM_2=[Empty()]), Merge(m_type='empty', sub_SM_1=[Convolution(fct_activation='tanh', kernel=2, nb_filter=12, padding='same', stride=1), Convolution(fct_activation='relu', kernel=2, nb_filter=12, padding='same', stride=1)], sub_SM_2=[Empty()]), BatchNormalisation(epsilon=1.1e-05), Convolution(fct_activation='tanh', kernel=1, nb_filter=24, padding='valid', stride=1), GlobalPooling(op='max'), Dense(fct_activation='softmax', nb_neurones=10)]\n",
      "archi_V4_test.json\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "architecture = list()\n",
    "\n",
    "nb_filter_value = 1 # init nb feature map\n",
    "output_size = 28\n",
    "\n",
    "# add input Layer\n",
    "architecture.append(InputLayer(shape=[28,28,1]))\n",
    "\n",
    "# add extraction feature (succession of Pooling/convolution)\n",
    "# Pooling can't be follow by a Pooling\n",
    "pooling = True\n",
    "code = 1 # we can add new layer\n",
    "j = 6\n",
    "last_layer = architecture[len(architecture)-1]\n",
    "\n",
    "while( ((isinstance(last_layer, Dropout)) | (isinstance(last_layer, BatchNormalisation))) | \n",
    "      (output_size == 28) | \n",
    "      ((stop(len(architecture),7)) & (code == 1))):\n",
    "    \n",
    "    layer = getlayer(architecture[len(architecture)-1], architecture[len(architecture)-2])\n",
    "    \n",
    "    \n",
    "    if (layer == Merge):\n",
    "        architecture, output_size = build_merge(architecture, output_size, nb_filter_value)\n",
    "    else:\n",
    "        \n",
    "        if(layer == Convolution):\n",
    "            nb_filter_value = nb_filter_value*j\n",
    "            j=2\n",
    "        add_layer = construct_layer(layer, nb_filter_value)\n",
    "\n",
    "        code, architecture, output_size = addLayer(architecture, add_layer, output_size)\n",
    "        last_layer = architecture[len(architecture)-1]\n",
    "\n",
    "\n",
    "try:\n",
    "    nb_filter_value = architecture[len(architecture)-1]['nb_filter']\n",
    "except:\n",
    "    nb_filter_value = int(nb_filter_value/2)\n",
    "    \n",
    "\n",
    "print(\"output size : \" + str(output_size))\n",
    "print(\"nb_filter : \" + str(nb_filter_value))\n",
    "print(\"code: \" + str(code))\n",
    "\n",
    "clf_layer = classification[random.randrange(2)]\n",
    "print(clf_layer)\n",
    "if clf_layer == Flatten:\n",
    "    \n",
    "    # add flatten layer\n",
    "    architecture.append(Flatten())\n",
    "    \n",
    "    \n",
    "    # compute parameters\n",
    "    param = output_size*output_size*(nb_filter_value)\n",
    "    print('param : ' + str(param))\n",
    "\n",
    "\n",
    "    ## init values\n",
    "    nb=0\n",
    "    if (param >= 1000):\n",
    "        nb_neurones = int(param*20/100)\n",
    "        print(\"=====\")\n",
    "        print(\"iteration\" + str(nb))\n",
    "        print(\"nb_neurone : \" + str(nb_neurones))\n",
    "        dense = Dense(\n",
    "            nb_neurones = nb_neurones,\n",
    "            fct_activation = fct_activation_value[random.randrange(3)]\n",
    "        )\n",
    "        architecture.append(dense)\n",
    "        nb+=1\n",
    "        nb_neurones = int(nb_neurones*20/100)\n",
    "\n",
    "    else:\n",
    "        pourcent = random.uniform(10,90)\n",
    "        nb_neurones = int(param*pourcent/100)\n",
    "\n",
    "    while(nb_neurones >= 1000):\n",
    "        print(\"=====\")\n",
    "        print(\"iteration\" + str(nb))\n",
    "        print(\"nb_neurone : \" + str(nb_neurones))\n",
    "        dense = Dense(\n",
    "            nb_neurones = nb_neurones,\n",
    "            fct_activation = fct_activation_value[random.randrange(3)]\n",
    "        )\n",
    "        architecture.append(dense)\n",
    "        nb+=1\n",
    "        nb_neurones = int(nb_neurones*20/100)\n",
    "\n",
    "\n",
    "    ## add dense Layers\n",
    "    while(nb_neurones > nb_class*10):\n",
    "        print(\"=====\")\n",
    "        print(\"iteration\" + str(nb))\n",
    "        print(\"nb_neurone : \" + str(nb_neurones))\n",
    "\n",
    "        dense = Dense(\n",
    "            nb_neurones = nb_neurones,\n",
    "            fct_activation = fct_activation_value[random.randrange(3)]\n",
    "        )\n",
    "        architecture.append(dense)\n",
    "\n",
    "\n",
    "        #incrementation\n",
    "        pourcent = random.uniform(10,90)\n",
    "        nb+=1\n",
    "        nb_neurones = int(nb_neurones*pourcent/100)\n",
    "\n",
    "elif (clf_layer == GlobalPooling):\n",
    "    architecture.append(GlobalPooling(op=op_value[random.randrange(2)]))\n",
    "else: print(\"clf error\")\n",
    "\n",
    "\n",
    "last_dense = Dense(\n",
    "    nb_neurones = nb_class,\n",
    "    fct_activation=\"softmax\"           \n",
    ")\n",
    "\n",
    "architecture.append(last_dense)            \n",
    "        \n",
    "        \n",
    "print(architecture)\n",
    "\n",
    "\n",
    "# create file\n",
    "file_name = \"archi_V4_test.json\"\n",
    "print(file_name)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "create_json_file(architecture, file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ecda0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64740d29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
