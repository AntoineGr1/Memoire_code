{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a4470016",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jsonobject import *\n",
    "import numpy as np \n",
    "import random\n",
    "import math\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "7488ee9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649ac400",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "5e885173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution\n",
    "class Convolution(JsonObject):\n",
    "    kernel = IntegerProperty()\n",
    "    padding = StringProperty()\n",
    "    stride = IntegerProperty()\n",
    "    nb_filter = IntegerProperty()\n",
    "    fct_activation = StringProperty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "289249b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input \n",
    "class InputLayer(JsonObject):\n",
    "    shape = ListProperty(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a60167d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pooling Avg/Max\n",
    "class Pooling(JsonObject):\n",
    "    op = StringProperty()\n",
    "    kernel = IntegerProperty(default=2)\n",
    "    padding = StringProperty(default=\"valid\")\n",
    "    stride = IntegerProperty(default=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f010355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Flatten\n",
    "class Flatten(JsonObject):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "d8b40a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense --> Fully connected layer\n",
    "class Dense(JsonObject):\n",
    "    nb_neurones =  IntegerProperty()\n",
    "    fct_activation = StringProperty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "63c0b3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batchnorm\n",
    "class BatchNormalisation(JsonObject):\n",
    "    epsilon = FloatProperty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "a5a61fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global pooling \n",
    "class GlobalPooling(JsonObject):\n",
    "    op = StringProperty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "c88668a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classe for the different possible merge add/concatenate\n",
    "class Merge(JsonObject):\n",
    "    m_type = StringProperty()\n",
    "    sub_SM_1 = ListProperty(JsonObject)\n",
    "    sub_SM_2 = ListProperty(JsonObject)\n",
    "    \n",
    "    def equals_sm1_sm2():\n",
    "        for i,j in sub_SM_1,sub_SM_2:\n",
    "            if (i != j):\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "431d96d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class dropout\n",
    "class Dropout(JsonObject):\n",
    "    dropout_rate = FloatProperty()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "aa7d7eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class that represente when the way of merge is empty\n",
    "class Empty(JsonObject):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16be5340",
   "metadata": {},
   "source": [
    "# Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "b291447b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table of hyperparameter value\n",
    "kernel_value = [1, 2, 3, 4, 5, 6, 7]\n",
    "stride_value = [1, 2, 3, 4, 5, 6, 7]\n",
    "padding_value = [\"valid\", \"same\"]\n",
    "fct_activation_value = [\"tanh\", \"relu\", \"selu\"]\n",
    "\n",
    "epsilon_value = [0, 1.001e-5, 0.001, 1.1e-5, 1.1e-7]\n",
    "dropout_value = [0, .1, .4, .5, .8, .01, .001]\n",
    "\n",
    "nb_layer_value = [1,2,3]\n",
    "nb_block_densenet_value = [1,2,3,4]\n",
    "\n",
    "nb_class = 10 # nb_class\n",
    "op_value = ['avg',\"max\"]\n",
    "\n",
    "m_type_value = [\"add\", \"concatenate\"]\n",
    "\n",
    "classification = [Flatten, GlobalPooling]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be668f9",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "848fafb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop(size_archi, x):\n",
    "    prob = (math.log(2*size_archi)*x)-(2*x)\n",
    "    if ( prob < random.randrange(101)):\n",
    "        return True\n",
    "    else : return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "b7b9c342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_json_file(archi, file_name):\n",
    "    directory = 'architecture_json/'\n",
    "    \n",
    "    # reset file\n",
    "    archi_file = open(directory+file_name, \"w\")\n",
    "    archi_file.close()\n",
    "    \n",
    "    # create file\n",
    "    \n",
    "    # open file\n",
    "    archi_file = open(directory+file_name, \"a\")\n",
    "    \n",
    "    archi_file.write(\"\"\"[\n",
    "    \"\"\")\n",
    "    \n",
    "    archi_size = len(archi)\n",
    "    i = 0\n",
    "    for l in archi:\n",
    "\n",
    "        str_layer = \"\"\"\\t{\n",
    "            'class':'\"\"\"\n",
    "        str_layer += l.__class__.__name__\n",
    "        str_layer +=\"\"\"',\\n\\t\\t\\t'parameters':\"\"\"\n",
    "        str_layer += str(l.to_json())\n",
    "        str_layer += \"\"\"\\n\\t\\t}\"\"\"\n",
    "        if(i < archi_size-1):\n",
    "            str_layer += \"\"\",\"\"\"\n",
    "            i+=1\n",
    "        str_layer = str_layer.replace(\"'\",\"\\\"\")\n",
    "        \n",
    "        archi_file.write(str_layer)\n",
    "        \n",
    "    archi_file.write(\"\"\"\\n]\"\"\")\n",
    "    archi_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e79d5d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add layer to architecture \n",
    "\n",
    "def addLayer(archi, layer, output_size):\n",
    "    input_size = output_size\n",
    "    feature_extra = archi[1:]\n",
    "    \n",
    "    if( isinstance(layer, Dropout) | isinstance(layer, BatchNormalisation)):\n",
    "        archi.append(layer)\n",
    "        return 1, archi, output_size\n",
    "    \n",
    "    # add layer if the architecture is empty\n",
    "    elif(feature_extra == []):\n",
    "        archi.append(layer)\n",
    "        return 1, archi, calcul_output(input_size, layer)\n",
    "    \n",
    "    else :\n",
    "        \n",
    "        # if we couldn't reduce more\n",
    "        #if(input_size == 1):\n",
    "        #    return 0, archi, input_size\n",
    "        \n",
    "        # if the output size got more than 1 we can add new layer\n",
    "        if(output_size >= 1): \n",
    "            output_size = calcul_output(input_size, layer)\n",
    "            \n",
    "            # if output size got negate is that the layer we want to add is wrong\n",
    "            if(output_size < 1 ):\n",
    "                return -1, archi, input_size\n",
    "            # if output size is bigger than 0 we can add new layer and continue\n",
    "            elif(output_size > 0):\n",
    "                archi.append(layer)\n",
    "                return 1, archi, output_size\n",
    "            # this should not append\n",
    "            else:\n",
    "                return \"Somethink wrong\"\n",
    "    # this should not append\n",
    "    return \"Error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "d310cc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the output \n",
    "# valid vs same\n",
    "def calcul_output(input_size, l):\n",
    "    output_size = 0\n",
    "    if(l.padding == \"valid\"):\n",
    "        kernel = l.kernel\n",
    "        stride = l.stride\n",
    "        while(input_size>=kernel):\n",
    "            input_size -= stride\n",
    "            output_size += 1   \n",
    "    else:\n",
    "        stride = l.stride\n",
    "        if(input_size%stride == 0):\n",
    "            output_size = int(input_size/stride)\n",
    "        else:\n",
    "            output_size = int(input_size/stride)+1\n",
    "    return output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "57296599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_merge(archi, output_size):\n",
    "    sub_sm1 = list()\n",
    "    sub_sm2 = list()\n",
    "    m_type = m_type_value[random.randrange(2)]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    m = Merge(m_type=m_type,\n",
    "             sub_SM_1=sub_sm1,\n",
    "             sub_SM_2=sub_sm2)\n",
    "    \n",
    "    \n",
    "    if(m.equals_sm1_sm2):\n",
    "        #build_merge(archi, output_size)\n",
    "        print(\"equals\")\n",
    "    else: \n",
    "        archi.append(m)\n",
    "        return archi , output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d0e36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution, Pooling, BatchNormalisation,  Dropout, Merge, Empty\n",
    "# Return list of layer compared to last layer for the sub state machine\n",
    "def getSub_SM_Layer():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "8de616e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution, Pooling, BatchNormalisation, Dropout, Merge\n",
    "# Return list of layer compared to last layer\n",
    "def getlayer(last_layer, prev_last_layer):\n",
    "    list_layer = list()\n",
    "    if(isinstance(last_layer, InputLayer)):\n",
    "        list_layer = [Convolution, BatchNormalisation, Merge]\n",
    "    elif(isinstance(last_layer, Convolution)):\n",
    "        list_layer = [Convolution, Pooling, BatchNormalisation,  Dropout, Merge]\n",
    "    elif(isinstance(last_layer, Pooling)):\n",
    "        list_layer = [Convolution, Merge]\n",
    "    elif(isinstance(last_layer, BatchNormalisation)):\n",
    "        if(isinstance(prev_last_layer, Convolution)):\n",
    "            list_layer = [Convolution, Merge, Pooling, Dropout]\n",
    "        else: list_layer = [Convolution]\n",
    "    elif(isinstance(last_layer, Dropout)):\n",
    "        list_layer = [Pooling]\n",
    "    return list_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f571dfc",
   "metadata": {},
   "source": [
    "# Creation Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "77f68bd3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "equals\n",
      "equals\n",
      "28\n",
      "1code\n",
      "hello 28\n",
      "25\n",
      "1code\n",
      "hello 25\n",
      "5\n",
      "1code\n",
      "5\n",
      "1code\n",
      "hello 5\n",
      "3\n",
      "1code\n",
      "hello 3\n",
      "3\n",
      "1code\n",
      "hello 3\n",
      "3\n",
      "1code\n",
      "3\n",
      "1code\n",
      "equals\n",
      "equals\n",
      "3\n",
      "1code\n",
      "hello 3\n",
      "3\n",
      "1code\n",
      "hello 3\n",
      "2\n",
      "1code\n",
      "2\n",
      "1code\n",
      "hello 2\n",
      "2\n",
      "1code\n",
      "hello 2\n",
      "2\n",
      "1code\n",
      "hello 2\n",
      "2\n",
      "1code\n",
      "hello 2\n",
      "2\n",
      "1code\n",
      "equals\n",
      "equals\n",
      "equals\n",
      "hello 2\n",
      "2\n",
      "1code\n",
      "[InputLayer(shape=[28, 28, 1]), BatchNormalisation(epsilon=0.001), Convolution(fct_activation='tanh', kernel=4, nb_filter=6, padding='valid', stride=1), Convolution(fct_activation='tanh', kernel=6, nb_filter=12, padding='same', stride=6), Dropout(dropout_rate=0.8), Pooling(kernel=3, op='max', padding='same', stride=2), Convolution(fct_activation='relu', kernel=1, nb_filter=24, padding='same', stride=1), Convolution(fct_activation='relu', kernel=1, nb_filter=48, padding='same', stride=1), BatchNormalisation(epsilon=1.1e-07), Dropout(dropout_rate=0.0), Pooling(kernel=1, op='max', padding='valid', stride=1), Convolution(fct_activation='relu', kernel=2, nb_filter=96, padding='same', stride=2), Dropout(dropout_rate=0.4), Pooling(kernel=1, op='max', padding='same', stride=1), Convolution(fct_activation='relu', kernel=1, nb_filter=192, padding='same', stride=1), Convolution(fct_activation='tanh', kernel=1, nb_filter=384, padding='same', stride=1), Pooling(kernel=1, op='avg', padding='valid', stride=1), Convolution(fct_activation='relu', kernel=1, nb_filter=768, padding='same', stride=1)]\n",
      "archi_V4_test.json\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "architecture = list()\n",
    "\n",
    "nb_filter_value = 1 # init nb feature map\n",
    "output_size = 28\n",
    "\n",
    "# add input Layer\n",
    "architecture.append(InputLayer(shape=[28,28,1]))\n",
    "\n",
    "# add extraction feature (succession of Pooling/convolution)\n",
    "# Pooling can't be follow by a Pooling\n",
    "pooling = True\n",
    "code = 1 # we can add new layer\n",
    "j = 6\n",
    "last_layer = architecture[len(architecture)-1]\n",
    "\n",
    "while( ((isinstance(last_layer, Dropout)) | (isinstance(last_layer, BatchNormalisation))) | \n",
    "      (output_size == 28) | \n",
    "      ((stop(len(architecture),7)) & (code == 1))):\n",
    "    list_layer = getlayer(architecture[len(architecture)-1], architecture[len(architecture)-2])\n",
    "    layer = list_layer[random.randrange(len(list_layer))]\n",
    "    \n",
    "    if (layer == Merge):\n",
    "        build_merge(architecture, output_size)\n",
    "    else:\n",
    "        \n",
    "        if(layer == Convolution):\n",
    "            nb_filter_value = nb_filter_value*j\n",
    "            j=2\n",
    "        \n",
    "        # Kernel <= output/2\n",
    "        if(output_size == 2):\n",
    "            kernel_value_filtered = [1,2]\n",
    "        elif(output_size == 1):\n",
    "            kernel_value_filtered = [1]\n",
    "        else: \n",
    "            kernel_value_filtered = [value for value in kernel_value if value <= math.ceil(output_size/2)]\n",
    "\n",
    "        kernel=kernel_value_filtered[random.randrange(len(kernel_value_filtered))]\n",
    "        \n",
    "        # kernel >= stride\n",
    "        stride_value_filtered = [value for value in stride_value if value <= kernel]\n",
    "        stride = stride_value_filtered[random.randrange(len(stride_value_filtered))]\n",
    "    \n",
    "        # if layer is Convolution\n",
    "        if(layer == Convolution):\n",
    "            add_layer = Convolution(\n",
    "                kernel=kernel, \n",
    "                padding=padding_value[random.randrange(2)], \n",
    "                stride=stride, \n",
    "                nb_filter= nb_filter_value,\n",
    "                fct_activation=fct_activation_value[random.randrange(3)]\n",
    "            )\n",
    "        # if is pooling\n",
    "        elif(layer == Pooling):\n",
    "            add_layer = Pooling(\n",
    "                op = op_value[random.randrange(2)],\n",
    "                kernel=kernel, \n",
    "                padding=padding_value[random.randrange(2)], \n",
    "                stride=stride\n",
    "            )\n",
    "        #if is BN\n",
    "        elif(layer == BatchNormalisation):\n",
    "            add_layer = BatchNormalisation(epsilon = epsilon_value[random.randrange(len(epsilon_value))])\n",
    "        \n",
    "        #if dropout\n",
    "        elif(layer == Dropout):\n",
    "            add_layer = Dropout(dropout_rate = dropout_value[random.randrange(len(dropout_value))])\n",
    "            \n",
    "        else: \n",
    "            print(\"error\")\n",
    "        \n",
    "        code, architecture, output_size = addLayer(architecture, add_layer, output_size)\n",
    "        print(output_size)\n",
    "        last_layer = architecture[len(architecture)-1]\n",
    "        print(str(code) + 'code')\n",
    "\n",
    "\n",
    "try:\n",
    "    nb_filter_value = architecture[len(architecture)-1]['nb_filter']\n",
    "except:\n",
    "    nb_filter_value = int(nb_filter_value/2)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "print(architecture)\n",
    "\n",
    "\n",
    "# create file\n",
    "file_name = \"archi_V4_test.json\"\n",
    "print(file_name)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "create_json_file(architecture, file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ecda0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64740d29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
